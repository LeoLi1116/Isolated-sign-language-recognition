{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["This is the notebook for GRU implementation.\n"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-05-06T18:52:32.837800Z","iopub.status.busy":"2023-05-06T18:52:32.837177Z","iopub.status.idle":"2023-05-06T18:53:34.515975Z","shell.execute_reply":"2023-05-06T18:53:34.514564Z","shell.execute_reply.started":"2023-05-06T18:52:32.837758Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow 2.11.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.20.3 which is incompatible.\n","tensorflow-transform 1.12.0 requires pyarrow<7,>=6, but you have pyarrow 5.0.0 which is incompatible.\n","tensorflow-serving-api 2.11.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.20.3 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mCollecting tflite-runtime\n","  Downloading tflite_runtime-2.11.0-cp37-cp37m-manylinux2014_x86_64.whl (2.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.19.2 in /opt/conda/lib/python3.7/site-packages (from tflite-runtime) (1.21.6)\n","Installing collected packages: tflite-runtime\n","Successfully installed tflite-runtime-2.11.0\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mCollecting ipdb\n","  Downloading ipdb-0.13.13-py3-none-any.whl (12 kB)\n","Requirement already satisfied: decorator in /opt/conda/lib/python3.7/site-packages (from ipdb) (5.1.1)\n","Requirement already satisfied: ipython>=7.31.1 in /opt/conda/lib/python3.7/site-packages (from ipdb) (7.34.0)\n","Requirement already satisfied: tomli in /opt/conda/lib/python3.7/site-packages (from ipdb) (2.0.1)\n","Requirement already satisfied: backcall in /opt/conda/lib/python3.7/site-packages (from ipython>=7.31.1->ipdb) (0.2.0)\n","Requirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.7/site-packages (from ipython>=7.31.1->ipdb) (0.1.6)\n","Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.7/site-packages (from ipython>=7.31.1->ipdb) (0.18.2)\n","Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.7/site-packages (from ipython>=7.31.1->ipdb) (4.8.0)\n","Requirement already satisfied: pygments in /opt/conda/lib/python3.7/site-packages (from ipython>=7.31.1->ipdb) (2.14.0)\n","Requirement already satisfied: pickleshare in /opt/conda/lib/python3.7/site-packages (from ipython>=7.31.1->ipdb) (0.7.5)\n","Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from ipython>=7.31.1->ipdb) (3.0.36)\n","Requirement already satisfied: traitlets>=4.2 in /opt/conda/lib/python3.7/site-packages (from ipython>=7.31.1->ipdb) (5.8.1)\n","Requirement already satisfied: setuptools>=18.5 in /opt/conda/lib/python3.7/site-packages (from ipython>=7.31.1->ipdb) (59.8.0)\n","Requirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/conda/lib/python3.7/site-packages (from jedi>=0.16->ipython>=7.31.1->ipdb) (0.8.3)\n","Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.7/site-packages (from pexpect>4.3->ipython>=7.31.1->ipdb) (0.7.0)\n","Requirement already satisfied: wcwidth in /opt/conda/lib/python3.7/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.31.1->ipdb) (0.2.6)\n","Installing collected packages: ipdb\n","Successfully installed ipdb-0.13.13\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mRequirement already satisfied: wandb in /opt/conda/lib/python3.7/site-packages (0.13.10)\n","Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from wandb) (59.8.0)\n","Requirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (2.28.2)\n","Requirement already satisfied: Click!=8.0.0,>=7.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (8.1.3)\n","Requirement already satisfied: PyYAML in /opt/conda/lib/python3.7/site-packages (from wandb) (6.0)\n","Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from wandb) (4.4.0)\n","Requirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (0.4.0)\n","Requirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (1.15.0)\n","Requirement already satisfied: setproctitle in /opt/conda/lib/python3.7/site-packages (from wandb) (1.3.2)\n","Requirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (5.9.3)\n","Requirement already satisfied: appdirs>=1.4.3 in /opt/conda/lib/python3.7/site-packages (from wandb) (1.4.4)\n","Requirement already satisfied: protobuf!=4.21.0,<5,>=3.12.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (3.20.3)\n","Requirement already satisfied: pathtools in /opt/conda/lib/python3.7/site-packages (from wandb) (0.1.2)\n","Requirement already satisfied: GitPython>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (3.1.30)\n","Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from Click!=8.0.0,>=7.0->wandb) (4.11.4)\n","Requirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.7/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.7/site-packages (from GitPython>=1.0.0->wandb) (4.0.10)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (3.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2022.12.7)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (1.26.14)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2.1.1)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.7/site-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (5.0.0)\n","Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->Click!=8.0.0,>=7.0->wandb) (3.11.0)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mCollecting hydra-core\n","  Downloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting antlr4-python3-runtime==4.9.*\n","  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n","\u001b[?25hRequirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from hydra-core) (23.0)\n","Requirement already satisfied: importlib-resources in /opt/conda/lib/python3.7/site-packages (from hydra-core) (5.10.2)\n","Collecting omegaconf<2.4,>=2.2\n","  Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: PyYAML>=5.1.0 in /opt/conda/lib/python3.7/site-packages (from omegaconf<2.4,>=2.2->hydra-core) (6.0)\n","Requirement already satisfied: zipp>=3.1.0 in /opt/conda/lib/python3.7/site-packages (from importlib-resources->hydra-core) (3.11.0)\n","Building wheels for collected packages: antlr4-python3-runtime\n","  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144575 sha256=824da28c2a2459853c0318f7d14791b4182bbeb49329442bb69edcd8384ada63\n","  Stored in directory: /root/.cache/pip/wheels/a9/8b/1f/b8233836d5798e3224c2442947e9639f220095de8bf46e800c\n","Successfully built antlr4-python3-runtime\n","Installing collected packages: antlr4-python3-runtime, omegaconf, hydra-core\n","Successfully installed antlr4-python3-runtime-4.9.3 hydra-core-1.3.2 omegaconf-2.3.0\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["try:\n","    import ipdb\n","except:\n","    !pip install -q --upgrade tensorflow-io\n","    !pip install tflite-runtime\n","    !pip install ipdb\n","    !pip install wandb\n","    !pip install hydra-core\n","    !mkdir models\n","    !cp -r /kaggle/input/gislr-extended-train-dataframe/extended_train.csv ./\n","    !cp -r /kaggle/input/asl-signs/train_landmark_files/16069/1004211348.parquet ."]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-05-06T18:53:34.520587Z","iopub.status.busy":"2023-05-06T18:53:34.520240Z","iopub.status.idle":"2023-05-06T18:53:34.543304Z","shell.execute_reply":"2023-05-06T18:53:34.542176Z","shell.execute_reply.started":"2023-05-06T18:53:34.520554Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Writing common_func.py\n"]}],"source":["%%writefile common_func.py\n","\n","import json\n","import os\n","import warnings\n","\n","from sklearn import metrics\n","\n","warnings.filterwarnings(\"ignore\")\n","os.environ[\"TF_DETERMINISTIC_OPS\"] = \"1\"\n","os.environ[\"TF_CUDNN_DETERMINISTIC\"] = \"1\"\n","os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n","import random\n","from pathlib import Path\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","import tensorflow_addons as tfa\n","from sklearn.model_selection import StratifiedGroupKFold\n","from tqdm.notebook import tqdm\n","from wandb.keras import WandbCallback, WandbMetricsLogger\n","\n","SAVE_DIR = \"./models/\"\n","# SAVE_DIR = \"/kaggle/working/models/\"\n","if Path(\"/kaggle/input/asl-signs/\").exists():\n","    DATA_DIR = \"/kaggle/input/asl-signs/\"\n","    ROOT_PATH = \"/kaggle/input/islr-external-data/\"\n","    CSV_PATH = \"./\"\n","else:\n","    DATA_DIR = \"/scratch/smart_data/islr_data/\"\n","    ROOT_PATH = \"/scratch/smart_data/\"\n","    CSV_PATH = \"/scratch/smart_data/islr_data/\"\n","\n","PARQ_PATH = \"/kaggle/input/asl-signs/\"\n","NUMPY_PATH = \"/scratch/smart_data/numpy_files/\"\n","LANDMARK_FILES_DIR = f\"{ROOT_PATH}train_landmark_files\"\n","TRAIN_FILE = f\"{CSV_PATH}extended_new.csv\"\n","\n","ROWS_PER_FRAME =543\n","\n","# Data Generation ###################################################################################\n","\n","def tf_nan_mean(x, axis=0):\n","    return tf.reduce_sum(tf.where(tf.math.is_nan(x), tf.zeros_like(x), x), axis=axis) / tf.reduce_sum(tf.where(tf.math.is_nan(x), tf.zeros_like(x), tf.ones_like(x)), axis=axis)\n","\n","def tf_nan_std(x, axis=0):\n","    d = x - tf_nan_mean(x, axis=axis)\n","    return tf.math.sqrt(tf_nan_mean(d * d, axis=axis))\n","\n","def flatten_means_and_stds(x, axis=0):\n","    # Get means and stds\n","    x_mean = tf_nan_mean(x, axis=0)\n","    x_std  = tf_nan_std(x,  axis=0)\n","\n","    x_out = tf.concat([x_mean, x_std], axis=0)\n","    x_out = tf.reshape(x_out, (1, INPUT_SHAPE[1]*2))\n","    x_out = tf.where(tf.math.is_finite(x_out), x_out, tf.zeros_like(x_out))\n","    return x_out\n","\n","class FeatureGen(tf.keras.layers.Layer):\n","    def __init__(self):\n","        super(FeatureGen, self).__init__()\n","    \n","    def call(self, x_in):\n","#         print(right_hand_percentage(x))\n","#         x_list = [tf.expand_dims(tf_nan_mean(x_in[:, av_set[0]:av_set[0]+av_set[1], :], axis=1), axis=1) for av_set in averaging_sets]\n","#         x_list.append(tf.gather(x_in, point_landmarks, axis=1))\n","#         x = tf.concat(x_list, 1)\n","        x = tf.gather(x_in, point_landmarks, axis=1)\n","\n","        x_padded = x\n","        for i in range(SEGMENTS):\n","            p0 = tf.where( ((tf.shape(x_padded)[0] % SEGMENTS) > 0) & ((i % 2) != 0) , 1, 0)\n","            p1 = tf.where( ((tf.shape(x_padded)[0] % SEGMENTS) > 0) & ((i % 2) == 0) , 1, 0)\n","            paddings = [[p0, p1], [0, 0], [0, 0]]\n","            x_padded = tf.pad(x_padded, paddings, mode=\"SYMMETRIC\")\n","        x_list = tf.split(x_padded, SEGMENTS)\n","        x_list = [flatten_means_and_stds(_x, axis=0) for _x in x_list]\n","\n","        x_list.append(flatten_means_and_stds(x, axis=0))\n","        \n","        ## Resize only dimension 0. Resize can't handle nan, so replace nan with that dimension's avg value to reduce impact.\n","        x = tf.image.resize(tf.where(tf.math.is_finite(x), x, tf_nan_mean(x, axis=0)), [NUM_FRAMES, LANDMARKS])\n","        x = tf.reshape(x, (1, INPUT_SHAPE[0]*INPUT_SHAPE[1]))\n","        x = tf.where(tf.math.is_nan(x), tf.zeros_like(x), x)\n","        x_list.append(x)\n","        x = tf.concat(x_list, axis=1)\n","        return x\n","\n","def convert_row(row, right_handed=True):\n","    x = load_relevant_data_subset(os.path.join(\"/kaggle/input/asl-signs\", row[1].path))\n","    x = feature_converter(tf.convert_to_tensor(x)).cpu().numpy()\n","    return x, row[1].label\n","\n","def convert_and_save_data():\n","    df = pd.read_csv(TRAIN_FILE)\n","    df['label'] = df['sign'].map(label_map)\n","    total = df.shape[0]\n","    if QUICK_TEST:\n","        total = QUICK_LIMIT\n","    npdata = np.zeros((total, INPUT_SHAPE[0]*INPUT_SHAPE[1] + (SEGMENTS+1)*INPUT_SHAPE[1]*2))\n","    nplabels = np.zeros(total)\n","    for i, row in tqdm(enumerate(df.iterrows()), total=total):\n","        (x,y) = convert_row(row)\n","        npdata[i,:] = x\n","        nplabels[i] = y\n","        if QUICK_TEST and i == QUICK_LIMIT - 1:\n","            break\n","    \n","    np.save(\"feature_data.npy\", npdata)\n","    np.save(\"feature_labels.npy\", nplabels)\n","    \n","\n","def right_hand_percentage(x):\n","    right = tf.gather(x, right_hand_landmarks, axis=1)\n","    left = tf.gather(x, left_hand_landmarks, axis=1)\n","    right_count = tf.reduce_sum(tf.where(tf.math.is_nan(right), tf.zeros_like(right), tf.ones_like(right)))\n","    left_count = tf.reduce_sum(tf.where(tf.math.is_nan(left), tf.zeros_like(left), tf.ones_like(left)))\n","    return right_count / (left_count+right_count)\n","\n","\n","# Data Functions ###################################################################################\n","\n","\n","def prepare_main_csv(seed, num_splits, csv_path=CSV_PATH):\n","    if Path(f\"{csv_path}/extended_new.csv\").exists():\n","        data_csv = pd.read_csv(f\"{csv_path}/extended_new.csv\").reset_index(drop=True)\n","    else:\n","        data_csv = pd.read_csv(f\"{csv_path}/extended_train.csv\").reset_index(drop=True)\n","\n","        json_data = read_json_file()\n","        json_df = pd.DataFrame.from_dict(json_data, orient=\"index\")\n","        json_df = json_df.reset_index()\n","        json_df.rename(columns={\"index\": \"sign\", 0: \"sign_val\"}, inplace=True)\n","\n","        data_csv = pd.merge(data_csv, json_df, on=\"sign\")\n","        data_csv = data_csv.sample(frac=1.0, random_state=seed).reset_index(drop=True)\n","        data_csv[\"hand\"] = data_csv[\"participant_id\"]\n","        data_csv = data_csv.replace({\"hand\": di})\n","        data_csv[\"fold_split\"] = (\n","            data_csv[\"hand\"].astype(\"str\") + \"_\" + data_csv[\"sign_val\"].astype(\"str\")\n","        )\n","\n","        # Splitting the data based on (hand & sign), grouped by participant_id\n","        skf = StratifiedGroupKFold(n_splits=num_splits)\n","        data_csv[\"fold\"] = -1\n","        print(\"Splitting Data ------------------------------------>\")\n","        for i, (train_index, test_index) in enumerate(\n","            skf.split(data_csv.index, data_csv.fold_split, data_csv.participant_id)\n","        ):\n","            data_csv.loc[test_index, \"fold\"] = i\n","            print(f\"fold {i} --> {len(test_index)}\")\n","            print(data_csv.loc[test_index].participant_id.value_counts())\n","        \n","        data_csv.to_csv(f\"{csv_path}/extended_new.csv\", index=False)\n","\n","    return data_csv\n","\n","\n","def get_data(fold_num, cfg):\n","    # Data Loading\n","    print(\"Data Loading ----->\")\n","    # train_x_full = np.load(f\"{ROOT_PATH}23_nonorm_feature_data.npy\").astype(np.float32)\n","    # train_y_full = np.load(f\"{ROOT_PATH}23_nonorm_feature_labels.npy\").astype(np.uint8)\n","    train_x_full = np.load(f\"{ROOT_PATH}feature_data.npy\").astype(np.float32)\n","    train_y_full = np.load(f\"{ROOT_PATH}feature_labels.npy\").astype(np.uint8)\n","\n","    print(train_x_full.shape, train_y_full.shape)\n","\n","    if cfg['FLAG_DROP_Z']:\n","        train_x_full = np.reshape(train_x_full, [train_x_full.shape[0], -1, 3])\n","        train_x_full = train_x_full[:, :, 0:2]\n","        train_x_full = np.reshape(train_x_full, [train_x_full.shape[0], -1])\n","        print(train_x_full.shape, train_y_full.shape)\n","\n","    # Remove it with stratifiedkfold\n","    train_df = prepare_main_csv(cfg['SEED'], cfg['NUM_SPLITS'])\n","    train_idxs = train_df.index[train_df.fold != fold_num].to_numpy()\n","    val_idxs = train_df.index[train_df.fold == fold_num].to_numpy()\n","\n","    train_x, train_y = train_x_full[train_idxs], train_y_full[train_idxs]\n","    val_x, val_y = train_x_full[val_idxs], train_y_full[val_idxs]\n","\n","    del train_x_full, train_y_full, train_idxs, val_idxs\n","\n","    print(train_df[train_df.sequence_id == 1004211348])\n","    return train_df, train_x, train_y, val_x, val_y\n","\n","\n","# Utils ###################################################################################\n","\n","def get_input_shape(num_frames, landmarks, flag_drop_z):\n","    input_shape = (num_frames, landmarks * 3)\n","\n","    if flag_drop_z:\n","        num_coords = 2\n","    else:\n","        num_coords = 3\n","\n","    return (num_frames, landmarks * num_coords)\n","\n","\n","def seed_it_all(seed=42):\n","    \"\"\"Attempt to be Reproducible\"\"\"\n","    tf.keras.backend.clear_session()\n","    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    tf.random.set_seed(seed)\n","    tf.keras.utils.set_random_seed(seed)\n","    tf.config.experimental.enable_op_determinism()\n","\n","\n","def read_json_file(file_path=f\"{DATA_DIR}/sign_to_prediction_index_map.json\"):\n","    with open(file_path, \"r\") as file:\n","        json_data = json.load(file)\n","    return json_data\n","\n","\n","def load_relevant_data_subset(pq_path):\n","    data_columns = [\"x\", \"y\", \"z\"]\n","    data = pd.read_parquet(pq_path, columns=data_columns)\n","    n_frames = int(len(data) / ROWS_PER_FRAME)\n","    data = data.values.reshape(n_frames, ROWS_PER_FRAME, len(data_columns))\n","    return data.astype(np.float32)\n","\n","\n","def load_npz(f):\n","    data = np.load(f)\n","    return data[\"data\"]\n","\n","\n","def uniform_soup():\n","    soups = []\n","    ## Instantiating model\n","\n","    tf.keras.backend.clear_session()\n","    model = get_model()\n","    model_paths = Path(SAVE_DIR).glob(\"*.h5\")\n","\n","    ## Iterating Over all models\n","    for path in tqdm(model_paths):\n","        ## loading model wieghts\n","        print(f\"### Loading {path}\")\n","        model.load_weights(str(path))\n","\n","        ## Adding model weights in soup list\n","        soup = [np.array(weights) for weights in model.weights]\n","        soups.append(soup)\n","\n","    ## Averaing all weights\n","    mean_soup = np.array(soups).mean(axis=0)\n","\n","    ## Replacing model's weight with Unifrom Soup Weights\n","    for w1, w2 in zip(model.weights, mean_soup):\n","        tf.keras.backend.set_value(w1, w2)\n","\n","    model.save_weights(f\"{SAVE_DIR}/uniform_soup.h5\")\n","\n","\n","class TFLiteModel(tf.Module):\n","    \"\"\"\n","    TensorFlow Lite model that takes input tensors and applies:\n","        – a preprocessing model\n","        – the ASL model\n","    \"\"\"\n","\n","    def __init__(self, asl_model):\n","        \"\"\"\n","        Initializes the TFLiteModel with the specified feature generation model and main model.\n","        \"\"\"\n","        super(TFLiteModel, self).__init__()\n","\n","        # Load the feature generation and main models\n","        self.prep_inputs = FeatureGen()\n","        self.asl_model = asl_model\n","\n","    @tf.function(\n","        input_signature=[\n","            tf.TensorSpec(shape=[None, 543, 3], dtype=tf.float32, name=\"inputs\")\n","        ]\n","    )\n","    def __call__(self, inputs):\n","        \"\"\"\n","        Applies the feature generation model and main model to the input tensors.\n","\n","        Args:\n","            inputs: Input tensor with shape [batch_size, 543, 3].\n","\n","        Returns:\n","            A dictionary with a single key 'outputs' and corresponding output tensor.\n","        \"\"\"\n","        x = self.prep_inputs(tf.cast(inputs, dtype=tf.float32))\n","        outputs = self.asl_model(x)[0, :]\n","\n","        # Return a dictionary with the output tensor\n","        return {\"outputs\": outputs}\n","\n","\n","# Metrics ###################################################################################\n","\n","label_ls = list(range(0, 250))\n","AVG_TYPE = \"weighted\"\n","\n","\n","def get_metrics(labels, preds_class):\n","    metric_dict = {\n","        \"accuracy\": metrics.accuracy_score(labels, preds_class),\n","        \"f1_score\": metrics.f1_score(\n","            labels, preds_class, labels=label_ls, zero_division=0, average=AVG_TYPE\n","        ),\n","        \"precision\": metrics.precision_score(\n","            labels, preds_class, labels=label_ls, zero_division=0, average=AVG_TYPE\n","        ),\n","        \"recall\": metrics.recall_score(\n","            labels, preds_class, labels=label_ls, zero_division=0, average=AVG_TYPE\n","        ),\n","        # 'roc': metrics.roc_auc_score(labels, preds_softmax, average='macro', multi_class='ovo', labels=label_ls),\n","    }\n","    for k, v in metric_dict.items():\n","        print(k, v)\n","\n","\n","def compute_evaluation_metrics(model, data_x, data_y, decoder):\n","    \"\"\"\n","    Computes the evaluation metrics for the given model on the given data and prints classwise confusion matrix.\n","\n","    Args:\n","    - model: The trained model to evaluate.\n","    - data_x: The input data to evaluate the model on.\n","    - data_y: The target data to evaluate the model on.\n","    - decoder: A function to decode the model's output into readable text.\n","    \"\"\"\n","    # Compute the predicted classes and confusion matrix\n","    batch_size = 1024\n","    y_pred = model.predict(data_x, batch_size=1024)\n","    print(y_pred.shape)\n","    y_pred_classes = tf.cast(np.argmax(y_pred, axis=1), tf.uint8)\n","    confusion_mtx = tf.math.confusion_matrix(data_y, y_pred_classes)\n","\n","    # Compute the evaluation metrics by class\n","    num_classes = confusion_mtx.shape[0]\n","    classwise_performance = {}\n","    for i in range(num_classes):\n","        tp = confusion_mtx[i, i]\n","        fp = tf.reduce_sum(confusion_mtx[:, i]) - tp\n","        fn = tf.reduce_sum(confusion_mtx[i, :]) - tp\n","        tn = tf.reduce_sum(confusion_mtx[i]) - (tp - fp - fn)\n","\n","        classwise_performance[i] = dict(\n","            accuracy=(tp + tn) / (tp + fp + tn + fn),\n","            precision=tp / (tp + fp),\n","            recall=tp / (tp + fn),\n","        )\n","        classwise_performance[i][\"f1_score\"] = (\n","            2\n","            * (\n","                classwise_performance[i][\"precision\"]\n","                * classwise_performance[i][\"recall\"]\n","            )\n","            / (\n","                classwise_performance[i][\"precision\"]\n","                + classwise_performance[i][\"recall\"]\n","            )\n","        )\n","\n","    # Sort the classwise performance by f1_score and print the results\n","    classwise_performance = dict(\n","        sorted(\n","            classwise_performance.items(), key=lambda x: x[1][\"f1_score\"], reverse=True\n","        )\n","    )\n","    print(\"\\n\\n... CLASSWISE CONFUSION MATRIX... \\n\")\n","    for i, perf in classwise_performance.items():\n","        print(\n","            f\"Class {i:<3}  ({decoder[i]:^13})  -->  Accuracy: {perf['accuracy']:.2f}, Precision: {perf['precision']:.2f}, Recall: {perf['recall']:.2f}, F1 Score: {perf['f1_score']:.2f}\"\n","        )\n","\n","\n","# Model Utils ################################################################################\n","\n","output_bias = tf.keras.initializers.Constant(1.0 / 250.0)\n","\n","\n","class MSD(tf.keras.layers.Layer):\n","    def __init__(\n","        self,\n","        units,\n","        fold_num,\n","        cfg,\n","        **kwargs,\n","    ):\n","        super().__init__(**kwargs)\n","\n","        self.lin = tf.keras.layers.Dense(\n","            units,\n","            activation=None,\n","            use_bias=True,\n","            bias_initializer=output_bias,\n","            # kernel_regularizer=R.l2(WEIGHT_REGULARIZE)\n","        )\n","\n","        rate_dropout = cfg[\"MSD_DROPOUT\"]\n","        if cfg[\"MSD_DROP_TYPE\"] == \"normal\":\n","            self.dropouts = [\n","                tf.keras.layers.Dropout((rate_dropout - 0.2), seed=135 + fold_num),\n","                tf.keras.layers.Dropout((rate_dropout - 0.1), seed=690 + fold_num),\n","                tf.keras.layers.Dropout((rate_dropout), seed=275 + fold_num),\n","                tf.keras.layers.Dropout((rate_dropout + 0.1), seed=348 + fold_num),\n","                tf.keras.layers.Dropout((rate_dropout + 0.2), seed=861 + fold_num),\n","            ]\n","\n","        elif cfg[\"MSD_DROP_TYPE\"] == \"gaussian\":\n","            self.dropouts = [\n","                tf.keras.layers.GaussianDropout((rate_dropout - 0.2)),\n","                tf.keras.layers.GaussianDropout((rate_dropout - 0.1)),\n","                tf.keras.layers.GaussianDropout(rate_dropout),\n","                tf.keras.layers.GaussianDropout((rate_dropout + 0.1)),\n","                tf.keras.layers.GaussianDropout((rate_dropout + 0.2)),\n","            ]\n","\n","    def call(self, inputs):\n","        for ii, drop in enumerate(self.dropouts):\n","            if ii == 0:\n","                out = self.lin(drop(inputs)) / 5.0\n","            else:\n","                out += self.lin(drop(inputs)) / 5.0\n","        return out\n","\n","\n","class ResidualBlock(tf.keras.layers.Layer):\n","    def __init__(self, units, dropout):\n","        super().__init__()\n","        self.linear = tf.keras.layers.Dense(units)\n","        self.bn = tf.keras.layers.BatchNormalization()\n","        self.act = tf.keras.layers.Activation(\"gelu\")\n","        if dropout != 0:\n","            self.drop = tf.keras.layers.Dropout(dropout)\n","            self.flag_use_drop = True\n","        else:\n","            self.flag_use_drop = False\n","\n","    def call(self, x):\n","        x = self.linear(x)\n","        x = self.bn(x)\n","        x = self.act(x)\n","        if self.flag_use_drop:\n","            x = self.drop(x)\n","        return x\n","\n","\n","class GRUModel(tf.keras.layers.Layer):\n","    def __init__(self, units, dropout, num_blocks):\n","        super().__init__()\n","        self.start_gru = tf.keras.layers.GRU(\n","            units=units, dropout=0.0, return_sequences=True\n","        )\n","        self.end_gru = tf.keras.layers.GRU(\n","            units=units, dropout=dropout, return_sequences=False\n","        )\n","\n","        if (num_blocks - 2) > 0:\n","            self.gru_blocks = [\n","                tf.keras.layers.GRU(units=units, dropout=dropout, return_sequences=True)\n","                * (num_blocks - 2)\n","            ]\n","            self.flag_use_gru_blocks = True\n","        else:\n","            self.flag_use_gru_blocks = False\n","\n","    def call(self, x):\n","        x = self.start_gru(x)\n","        if self.flag_use_gru_blocks:\n","            for blk in self.gru_blocks:\n","                x = blk(x)\n","        x = self.end_gru(x)\n","        return x\n","\n","\n","def model_utils(cfg, fold_num):\n","    metric_ls = [\n","        tf.keras.metrics.SparseCategoricalAccuracy(),\n","        tf.keras.metrics.SparseTopKCategoricalAccuracy(k=5),\n","    ]\n","\n","    cb_list = [\n","        tf.keras.callbacks.EarlyStopping(\n","            patience=5,\n","            restore_best_weights=True,\n","            verbose=1,\n","            monitor=cfg[\"TARGET_METRIC\"],\n","        ),\n","        tf.keras.callbacks.ReduceLROnPlateau(patience=2, factor=0.8, verbose=1),\n","        tf.keras.callbacks.ModelCheckpoint(\n","            f\"{SAVE_DIR}/best_acc_{fold_num}.h5\",\n","            monitor=cfg[\"TARGET_METRIC\"],\n","            verbose=0,\n","            save_best_only=True,\n","            save_weights_only=True,\n","            mode=\"max\",\n","            save_freq=\"epoch\",\n","        ),\n","    ]\n","\n","    if cfg[\"FLAG_WANDB\"]:\n","        cb_list += [#WandbMetricsLogger()\n","            WandbCallback(\n","                monitor=cfg[\"TARGET_METRIC\"],\n","                log_weights=False,\n","                log_evaluation=False,\n","                save_model=False,\n","            )\n","        ]\n","\n","    opt = tfa.optimizers.AdamW(weight_decay=0, learning_rate=cfg[\"LR\"])\n","    # opt = tf.keras.optimizers.Adam(learning_rate=LR)\n","    # opt = tfa.optimizers.RectifiedAdam(learning_rate=LR)\n","    # opt = tfa.optimizers.Lookahead(opt, sync_period=5)\n","\n","    return metric_ls, cb_list, opt\n","\n","\n","######################################################################################################################\n","\n","lip_landmarks = [\n","    61,\n","    185,\n","    40,\n","    39,\n","    37,\n","    0,\n","    267,\n","    269,\n","    270,\n","    409,\n","    291,\n","    146,\n","    91,\n","    181,\n","    84,\n","    17,\n","    314,\n","    405,\n","    321,\n","    375,\n","    78,\n","    191,\n","    80,\n","    81,\n","    82,\n","    13,\n","    312,\n","    311,\n","    310,\n","    415,\n","    95,\n","    88,\n","    178,\n","    87,\n","    14,\n","    317,\n","    402,\n","    318,\n","    324,\n","    308,\n","]\n","\n","# Analyzing Handedness\n","left_handed_signer = [\n","    16069,\n","    32319,\n","    36257,\n","    22343,\n","    27610,\n","    61333,\n","    34503,\n","    55372,\n","    37055,\n","]  # both_hands_signer-> 37055\n","right_handed_signer = [\n","    26734,\n","    28656,\n","    25571,\n","    62590,\n","    29302,\n","    49445,\n","    53618,\n","    18796,\n","    4718,\n","    2044,\n","    37779,\n","    30680,\n","]\n","lip_landmarks = [\n","    61,\n","    185,\n","    40,\n","    39,\n","    37,\n","    0,\n","    267,\n","    269,\n","    270,\n","    409,\n","    291,\n","    146,\n","    91,\n","    181,\n","    84,\n","    17,\n","    314,\n","    405,\n","    321,\n","    375,\n","    78,\n","    191,\n","    80,\n","    81,\n","    82,\n","    13,\n","    312,\n","    311,\n","    310,\n","    415,\n","    95,\n","    88,\n","    178,\n","    87,\n","    14,\n","    317,\n","    402,\n","    318,\n","    324,\n","    308,\n","]\n","\n","di = {}\n","for k in left_handed_signer:\n","    di[k] = 0\n","for k in right_handed_signer:\n","    di[k] = 1\n","\n","left_hand_landmarks = list(range(468, 468 + 21))\n","right_hand_landmarks = list(range(522, 522 + 21))\n","\n","averaging_sets = [\n","    [0, 468],\n","    [489, 33],\n","]  ## average over the entire face, and the entire 'pose'\n","\n","point_landmarks = [\n","    item\n","    for sublist in [lip_landmarks, left_hand_landmarks, right_hand_landmarks]\n","    for item in sublist\n","]\n","\n","LANDMARKS = len(point_landmarks) #+ len(averaging_sets)\n","\n","# Fixed  ##################################################################################\n","\n","FLAG_DROP_Z = False\n","ROWS_PER_FRAME = 543\n","NUM_FRAMES = 15\n","INPUT_SHAPE = get_input_shape(NUM_FRAMES, LANDMARKS, FLAG_DROP_Z)\n","SEGMENTS = 3\n","NUM_BASE_FEATS = (SEGMENTS + 1) * INPUT_SHAPE[1] * 2\n","FLAT_FRAME_SHAPE = NUM_BASE_FEATS + (INPUT_SHAPE[0] * INPUT_SHAPE[1])\n","decoder = {v: k for k, v in read_json_file().items()}"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-05-06T18:53:34.546086Z","iopub.status.busy":"2023-05-06T18:53:34.545513Z","iopub.status.idle":"2023-05-06T18:53:34.575731Z","shell.execute_reply":"2023-05-06T18:53:34.574715Z","shell.execute_reply.started":"2023-05-06T18:53:34.546037Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Writing trainer.py\n"]}],"source":["%%writefile trainer.py\n","\n","import gc\n","import os\n","import pprint\n","import warnings\n","import wandb\n","import hydra\n","from omegaconf import DictConfig\n","from zipfile import ZipFile\n","try:\n","    import tflite_runtime.interpreter as tflite\n","    FLAG_INTERPRET = True\n","except:\n","    FLAG_INTERPRET = False\n","    print(\"TFlite Interpretation not possible\")\n","warnings.filterwarnings(\"ignore\")\n","os.environ[\"TF_DETERMINISTIC_OPS\"] = \"1\"\n","os.environ[\"TF_CUDNN_DETERMINISTIC\"] = \"1\"\n","os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n","import time\n","import numpy as np\n","import tensorflow as tf\n","from common_func import *\n","from tensorflow.keras.utils import plot_model\n","\n","seed_it_all()\n","start_time = time.time()\n","\n","# Flags  ##################################################################################\n","if False:\n","    mixed_precision.set_global_policy(\"mixed_float16\")\n","    tf.config.optimizer.set_jit(True)\n","\n","# Model  ###################################################################################\n","\n","\n","def get_model(\n","    cfg,\n","    fold_num=0,\n","    n_labels=250,\n","    flat_frame_len=FLAT_FRAME_SHAPE,\n","    flag_model_summary=False,\n","    flag_with_cb_list=False,\n","):\n","    print(\"Model Loading ----->\")\n","    _inputs = tf.keras.layers.Input(shape=(flat_frame_len,))\n","\n","    # import ipdb\n","    # ipdb.set_trace()\n","    x = _inputs[:, :NUM_BASE_FEATS]\n","    x_conv = tf.reshape(_inputs[:, NUM_BASE_FEATS:], (-1, NUM_FRAMES, INPUT_SHAPE[1]))\n","\n","    # Concat Dilated Convolutions with actual data\n","    gru_out = GRUModel(\n","        cfg[\"NUM_GRU_UNITS\"], cfg[\"RATE_GRU_DROPOUT\"], cfg[\"NUM_GRU_BLOCKS\"]\n","    )(x_conv)\n","    \n","    if cfg['FLAG_CONCAT_FEATS']:\n","        x = tf.keras.layers.concatenate([gru_out, x], axis=1)\n","    else:\n","        x = gru_out\n","    print(\"Concatenate Shape\", x.shape)\n","\n","    # Residual Block\n","    x = ResidualBlock(cfg[\"NUM_RESIDUAL_UNITS\"], 0.25)(x)\n","    x += ResidualBlock(cfg[\"NUM_RESIDUAL_UNITS\"], 0.0)(x)\n","\n","    # Final output MSD Layer\n","    x = MSD(units=n_labels, fold_num=fold_num, cfg=cfg)(x)\n","    _outputs = tf.keras.layers.Softmax(dtype=\"float32\")(x)\n","\n","    # Build the model\n","    model = tf.keras.models.Model(inputs=_inputs, outputs=_outputs)\n","    metric_ls, cb_list, opt = model_utils(cfg, fold_num)\n","    model.compile(opt, \"sparse_categorical_crossentropy\", metrics=metric_ls)\n","\n","    if flag_model_summary:\n","        model.summary()\n","\n","    if flag_with_cb_list:\n","        return model, cb_list\n","    else:\n","        return model\n","\n","\n","def tflite_conversion(model):    \n","    # TFLite Conversion\n","    tflite_keras_model = TFLiteModel(model)\n","    demo_output = tflite_keras_model(load_relevant_data_subset('1004211348.parquet'))[\"outputs\"]\n","    decoder[np.argmax(demo_output.numpy(), axis=-1)]\n","\n","    keras_model_converter = tf.lite.TFLiteConverter.from_keras_model(tflite_keras_model)\n","    tflite_model = keras_model_converter.convert()\n","    \n","    tf_lite_model_path = f'{SAVE_DIR}/model.tflite'\n","    with open(tf_lite_model_path, 'wb') as f:\n","        f.write(tflite_model)\n","        \n","    ZipFile('submission.zip', mode='w').write(tf_lite_model_path)\n","\n","    if FLAG_INTERPRET:\n","        interpreter = tflite.Interpreter(tf_lite_model_path)\n","        found_signatures = list(interpreter.get_signature_list().keys())\n","        prediction_fn = interpreter.get_signature_runner(\"serving_default\")\n","        output = prediction_fn(inputs=load_relevant_data_subset('1004211348.parquet'))\n","        sign = np.argmax(output[\"outputs\"])\n","\n","        print(\"PRED : \", decoder[sign])\n","        # print(\"GT   : \", train_df.sign[0])\n","\n","    \n","@hydra.main(version_base=None, config_path=\"./\", config_name=\"config\")\n","def my_app(cfg: DictConfig):\n","    print(\"*\" * 75)\n","    config = dict(cfg[\"CFG\"])\n","    seed_it_all(config[\"SEED\"])\n","    config[\"FLAG_DROP_Z\"] = FLAG_DROP_Z\n","    if config[\"FLAG_DEBUG\"]:\n","        config[\"NUM_EPOCHS\"] = 3\n","        config[\"FLAG_WANDB\"] = config[\"FLAG_WANDB\"] and False\n","    else:\n","        config[\"FLAG_WANDB\"] = config[\"FLAG_WANDB\"] and True\n","\n","    pprint.pprint(config)    \n","    true = np.array([])\n","    oof = np.array([])\n","    for fold_cnt, fold_num in enumerate(\n","        range(config[\"FOLD_START\"], config[\"FOLD_END\"]+1)\n","    ):\n","        print(\"#\" * 25)\n","        print(f\"### Fold {fold_num}\")\n","        if config[\"FLAG_WANDB\"]:\n","            wandb.init(project=\"isle_analysis\", group=config[\"DESCRIPTION\"])\n","\n","        seed_it_all(config[\"SEED\"] + fold_num)\n","        train_df, train_x, train_y, val_x, val_y = get_data(\n","            fold_num, config\n","        )\n","\n","        model, cb_list = get_model(\n","            config, fold_num, flag_with_cb_list=True, flag_model_summary=(fold_cnt == 0)\n","        )\n","        \n","        \n","\n","        plot_model(model, expand_nested=False)\n","\n","        history = model.fit(\n","            train_x,\n","            train_y,\n","            validation_data=(val_x, val_y),\n","            verbose=2,\n","            epochs=config[\"NUM_EPOCHS\"],\n","            callbacks=cb_list,\n","            batch_size=config[\"BATCH_SIZE\"],\n","            workers=8,\n","        )\n","\n","        oof_p = model.predict(val_x, batch_size=config[\"BATCH_SIZE\"], verbose=2)\n","        oof_p = np.argmax(oof_p, axis=1)\n","        true = np.concatenate([true, val_y])\n","        oof = np.concatenate([oof, oof_p])\n","\n","        print(\"#\" * 25)\n","        print(f\"### Evaluation Metrics\")\n","        model.evaluate(val_x, val_y)\n","\n","        if fold_num == config[\"FOLD_END\"]:\n","            compute_evaluation_metrics(model, val_x, val_y, decoder=decoder)\n","            \n","        del train_df, train_x, train_y, val_x, val_y\n","        gc.collect()\n","\n","        if config[\"FLAG_WANDB\"]:\n","            wandb.finish()\n","            \n","    # PRINT OVERALL RESULTS\n","    print(\"#\" * 25)\n","    print(f\"Overall Metrics\")\n","    get_metrics(true, oof)\n","    tf.keras.backend.clear_session()\n","\n","    if config[\"FLAG_GEN_TFLITE\"]:\n","        tflite_conversion(model)\n","        \n","    \n","if __name__ == \"__main__\":\n","    cfg = my_app()\n","    print(\"Total Time: \", time.time() - start_time)\n","\n","    # Dilated Convolutions\n","    # conv_1 = tf.keras.layers.Conv1D(5, 1, strides=1, activation='silu')(x_conv)\n","    # conv_3 = tf.keras.layers.Conv1D(5, 1, strides=3, activation='silu')(x_conv)\n","    # conv_5 = tf.keras.layers.Conv1D(5, 1, strides=5, activation='silu')(x_conv)\n","    # conv_15 = tf.keras.layers.Conv1D(5, 1, strides=15, activation='silu')(x_conv)\n","    # conv_out = tf.keras.layers.concatenate([conv_1, conv_3, conv_5, conv_15], axis=1)\n","    # conv_out = tf.reshape(conv_out, (-1, conv_out.shape[1] * conv_out.shape[2]))\n"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-05-06T18:53:34.578857Z","iopub.status.busy":"2023-05-06T18:53:34.578393Z","iopub.status.idle":"2023-05-06T18:53:34.590074Z","shell.execute_reply":"2023-05-06T18:53:34.588458Z","shell.execute_reply.started":"2023-05-06T18:53:34.578820Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Writing config.yaml\n"]}],"source":["%%writefile config.yaml\n","CFG:\n","    # General Params  ##########################################################################\n","\n","    DESCRIPTION: initial trials\n","    LR: 6e-4\n","    BATCH_SIZE: 512 # 512\n","    NUM_EPOCHS: 100\n","    NUM_SPLITS: 7\n","    TARGET_METRIC: \"val_sparse_categorical_accuracy\"\n","\n","    FOLD_START: 1\n","    FOLD_END: 1\n","    \n","    SEED: 42\n","    \n","    # Flags  ##################################################################################\n","    \n","    FLAG_DROP_Z: False\n","    FLAG_GEN_TFLITE: True\n","#     FLAG_GEN_TFLITE: False\n","    \n","    FLAG_CONCAT_FEATS: False # Use mean and standard deviation information captured in the dataset\n","\n","\n","    FLAG_DEBUG: False\n","#     FLAG_WANDB: True\n","    FLAG_WANDB: False\n","    # FLAG_DEBUG: True\n","\n","    # Model  ##################################################################################\n","\n","    # NUM_RESIDUAL_UNITS: 128\n","    NUM_RESIDUAL_UNITS: 1024\n","\n","    # NUM_GRU_UNITS: 128\n","    NUM_GRU_UNITS: 512\n","    RATE_GRU_DROPOUT: 0.5\n","    NUM_GRU_BLOCKS: 1 # 2 minimal value\n","\n","    MSD_DROP_TYPE: \"normal\"\n","    MSD_DROPOUT: 0.5"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-06T18:53:34.593227Z","iopub.status.busy":"2023-05-06T18:53:34.591801Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["***************************************************************************\n","{'BATCH_SIZE': 512,\n"," 'DESCRIPTION': 'initial trials',\n"," 'FLAG_CONCAT_FEATS': False,\n"," 'FLAG_DEBUG': False,\n"," 'FLAG_DROP_Z': False,\n"," 'FLAG_GEN_TFLITE': True,\n"," 'FLAG_WANDB': False,\n"," 'FOLD_END': 1,\n"," 'FOLD_START': 1,\n"," 'LR': 0.0006,\n"," 'MSD_DROPOUT': 0.5,\n"," 'MSD_DROP_TYPE': 'normal',\n"," 'NUM_EPOCHS': 100,\n"," 'NUM_GRU_BLOCKS': 1,\n"," 'NUM_GRU_UNITS': 512,\n"," 'NUM_RESIDUAL_UNITS': 1024,\n"," 'NUM_SPLITS': 7,\n"," 'RATE_GRU_DROPOUT': 0.5,\n"," 'SEED': 42,\n"," 'TARGET_METRIC': 'val_sparse_categorical_accuracy'}\n","#########################\n","### Fold 1\n","Data Loading ----->\n","(94477, 5658) (94477,)\n","Splitting Data ------------------------------------>\n","fold 0 --> 13920\n","49445    4968\n","22343    4677\n","27610    4275\n","Name: participant_id, dtype: int64\n","fold 1 --> 13417\n","36257    4896\n","53618    4656\n","25571    3865\n","Name: participant_id, dtype: int64\n","fold 2 --> 13072\n","16069    4848\n","29302    4722\n","18796    3502\n","Name: participant_id, dtype: int64\n","fold 3 --> 14026\n","61333    4900\n","62590    4563\n","28656    4563\n","Name: participant_id, dtype: int64\n","fold 4 --> 12946\n","55372    4826\n","37779    4782\n","30680    3338\n","Name: participant_id, dtype: int64\n","fold 5 --> 13062\n","2044     4810\n","32319    4753\n","4718     3499\n","Name: participant_id, dtype: int64\n","fold 6 --> 14034\n","26734    4841\n","37055    4648\n","34503    4545\n","Name: participant_id, dtype: int64\n","                                                    path  ...  fold\n","66511  /kaggle/input/asl-signs/train_landmark_files/1...  ...     2\n","\n","[1 rows x 25 columns]\n","Model Loading ----->\n","Concatenate Shape (None, 512)\n","Model: \"model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_1 (InputLayer)           [(None, 5658)]       0           []                               \n","                                                                                                  \n"," tf.__operators__.getitem_1 (Sl  (None, 3690)        0           ['input_1[0][0]']                \n"," icingOpLambda)                                                                                   \n","                                                                                                  \n"," tf.reshape (TFOpLambda)        (None, 15, 246)      0           ['tf.__operators__.getitem_1[0][0\n","                                                                 ]']                              \n","                                                                                                  \n"," gru_model (GRUModel)           (None, 512)          2743296     ['tf.reshape[0][0]']             \n","                                                                                                  \n"," residual_block (ResidualBlock)  (None, 1024)        529408      ['gru_model[0][0]']              \n","                                                                                                  \n"," residual_block_1 (ResidualBloc  (None, 1024)        1053696     ['residual_block[0][0]']         \n"," k)                                                                                               \n","                                                                                                  \n"," tf.__operators__.add (TFOpLamb  (None, 1024)        0           ['residual_block[0][0]',         \n"," da)                                                              'residual_block_1[0][0]']       \n","                                                                                                  \n"," msd (MSD)                      (None, 250)          256250      ['tf.__operators__.add[0][0]']   \n","                                                                                                  \n"," softmax (Softmax)              (None, 250)          0           ['msd[0][0]']                    \n","                                                                                                  \n","==================================================================================================\n","Total params: 4,582,650\n","Trainable params: 4,578,554\n","Non-trainable params: 4,096\n","__________________________________________________________________________________________________\n","Epoch 1/100\n","159/159 - 17s - loss: 5.0345 - sparse_categorical_accuracy: 0.0445 - sparse_top_k_categorical_accuracy: 0.1549 - val_loss: 4.3001 - val_sparse_categorical_accuracy: 0.0976 - val_sparse_top_k_categorical_accuracy: 0.3133 - lr: 6.0000e-04 - 17s/epoch - 107ms/step\n","Epoch 2/100\n","159/159 - 7s - loss: 3.5554 - sparse_categorical_accuracy: 0.1865 - sparse_top_k_categorical_accuracy: 0.4707 - val_loss: 3.4987 - val_sparse_categorical_accuracy: 0.1934 - val_sparse_top_k_categorical_accuracy: 0.4787 - lr: 6.0000e-04 - 7s/epoch - 41ms/step\n","Epoch 3/100\n","159/159 - 7s - loss: 2.8652 - sparse_categorical_accuracy: 0.3142 - sparse_top_k_categorical_accuracy: 0.6294 - val_loss: 2.7515 - val_sparse_categorical_accuracy: 0.3407 - val_sparse_top_k_categorical_accuracy: 0.6567 - lr: 6.0000e-04 - 7s/epoch - 42ms/step\n","Epoch 4/100\n","159/159 - 7s - loss: 2.4551 - sparse_categorical_accuracy: 0.4010 - sparse_top_k_categorical_accuracy: 0.7098 - val_loss: 3.1811 - val_sparse_categorical_accuracy: 0.2739 - val_sparse_top_k_categorical_accuracy: 0.5755 - lr: 6.0000e-04 - 7s/epoch - 41ms/step\n","Epoch 5/100\n","\n","Epoch 5: ReduceLROnPlateau reducing learning rate to 0.00048000002279877666.\n","159/159 - 7s - loss: 2.1941 - sparse_categorical_accuracy: 0.4572 - sparse_top_k_categorical_accuracy: 0.7549 - val_loss: 2.7955 - val_sparse_categorical_accuracy: 0.3451 - val_sparse_top_k_categorical_accuracy: 0.6574 - lr: 6.0000e-04 - 7s/epoch - 42ms/step\n","Epoch 6/100\n","159/159 - 7s - loss: 1.9528 - sparse_categorical_accuracy: 0.5130 - sparse_top_k_categorical_accuracy: 0.7924 - val_loss: 2.1159 - val_sparse_categorical_accuracy: 0.4892 - val_sparse_top_k_categorical_accuracy: 0.7653 - lr: 4.8000e-04 - 7s/epoch - 43ms/step\n","Epoch 7/100\n","159/159 - 7s - loss: 1.8185 - sparse_categorical_accuracy: 0.5433 - sparse_top_k_categorical_accuracy: 0.8125 - val_loss: 2.1570 - val_sparse_categorical_accuracy: 0.4658 - val_sparse_top_k_categorical_accuracy: 0.7651 - lr: 4.8000e-04 - 7s/epoch - 43ms/step\n","Epoch 8/100\n","159/159 - 7s - loss: 1.7105 - sparse_categorical_accuracy: 0.5684 - sparse_top_k_categorical_accuracy: 0.8275 - val_loss: 2.0377 - val_sparse_categorical_accuracy: 0.4992 - val_sparse_top_k_categorical_accuracy: 0.7787 - lr: 4.8000e-04 - 7s/epoch - 43ms/step\n","Epoch 9/100\n","159/159 - 7s - loss: 1.6123 - sparse_categorical_accuracy: 0.5894 - sparse_top_k_categorical_accuracy: 0.8404 - val_loss: 1.8235 - val_sparse_categorical_accuracy: 0.5532 - val_sparse_top_k_categorical_accuracy: 0.8138 - lr: 4.8000e-04 - 7s/epoch - 43ms/step\n","Epoch 10/100\n","159/159 - 7s - loss: 1.5234 - sparse_categorical_accuracy: 0.6096 - sparse_top_k_categorical_accuracy: 0.8542 - val_loss: 1.9410 - val_sparse_categorical_accuracy: 0.5146 - val_sparse_top_k_categorical_accuracy: 0.7987 - lr: 4.8000e-04 - 7s/epoch - 43ms/step\n","Epoch 11/100\n","\n","Epoch 11: ReduceLROnPlateau reducing learning rate to 0.00038400001358240843.\n","159/159 - 7s - loss: 1.4452 - sparse_categorical_accuracy: 0.6270 - sparse_top_k_categorical_accuracy: 0.8641 - val_loss: 1.8675 - val_sparse_categorical_accuracy: 0.5334 - val_sparse_top_k_categorical_accuracy: 0.8027 - lr: 4.8000e-04 - 7s/epoch - 42ms/step\n","Epoch 12/100\n","159/159 - 7s - loss: 1.3287 - sparse_categorical_accuracy: 0.6568 - sparse_top_k_categorical_accuracy: 0.8785 - val_loss: 1.9878 - val_sparse_categorical_accuracy: 0.5129 - val_sparse_top_k_categorical_accuracy: 0.7901 - lr: 3.8400e-04 - 7s/epoch - 42ms/step\n","Epoch 13/100\n","159/159 - 7s - loss: 1.2786 - sparse_categorical_accuracy: 0.6656 - sparse_top_k_categorical_accuracy: 0.8846 - val_loss: 1.5855 - val_sparse_categorical_accuracy: 0.6180 - val_sparse_top_k_categorical_accuracy: 0.8464 - lr: 3.8400e-04 - 7s/epoch - 42ms/step\n","Epoch 14/100\n","159/159 - 7s - loss: 1.2153 - sparse_categorical_accuracy: 0.6836 - sparse_top_k_categorical_accuracy: 0.8931 - val_loss: 1.7622 - val_sparse_categorical_accuracy: 0.5595 - val_sparse_top_k_categorical_accuracy: 0.8260 - lr: 3.8400e-04 - 7s/epoch - 41ms/step\n","Epoch 15/100\n","\n","Epoch 15: ReduceLROnPlateau reducing learning rate to 0.00030720001086592674.\n","159/159 - 7s - loss: 1.1819 - sparse_categorical_accuracy: 0.6894 - sparse_top_k_categorical_accuracy: 0.8973 - val_loss: 1.5933 - val_sparse_categorical_accuracy: 0.6159 - val_sparse_top_k_categorical_accuracy: 0.8495 - lr: 3.8400e-04 - 7s/epoch - 42ms/step\n","Epoch 16/100\n","159/159 - 7s - loss: 1.0909 - sparse_categorical_accuracy: 0.7133 - sparse_top_k_categorical_accuracy: 0.9077 - val_loss: 1.3961 - val_sparse_categorical_accuracy: 0.6567 - val_sparse_top_k_categorical_accuracy: 0.8685 - lr: 3.0720e-04 - 7s/epoch - 42ms/step\n","Epoch 17/100\n","159/159 - 7s - loss: 1.0481 - sparse_categorical_accuracy: 0.7240 - sparse_top_k_categorical_accuracy: 0.9127 - val_loss: 1.8209 - val_sparse_categorical_accuracy: 0.5611 - val_sparse_top_k_categorical_accuracy: 0.8181 - lr: 3.0720e-04 - 7s/epoch - 42ms/step\n","Epoch 18/100\n","159/159 - 7s - loss: 1.0195 - sparse_categorical_accuracy: 0.7298 - sparse_top_k_categorical_accuracy: 0.9158 - val_loss: 1.3909 - val_sparse_categorical_accuracy: 0.6514 - val_sparse_top_k_categorical_accuracy: 0.8693 - lr: 3.0720e-04 - 7s/epoch - 41ms/step\n","Epoch 19/100\n","159/159 - 7s - loss: 0.9828 - sparse_categorical_accuracy: 0.7373 - sparse_top_k_categorical_accuracy: 0.9196 - val_loss: 1.3133 - val_sparse_categorical_accuracy: 0.6773 - val_sparse_top_k_categorical_accuracy: 0.8778 - lr: 3.0720e-04 - 7s/epoch - 43ms/step\n","Epoch 20/100\n","159/159 - 7s - loss: 0.9504 - sparse_categorical_accuracy: 0.7455 - sparse_top_k_categorical_accuracy: 0.9244 - val_loss: 1.5002 - val_sparse_categorical_accuracy: 0.6277 - val_sparse_top_k_categorical_accuracy: 0.8564 - lr: 3.0720e-04 - 7s/epoch - 42ms/step\n","Epoch 21/100\n","159/159 - 7s - loss: 0.9095 - sparse_categorical_accuracy: 0.7555 - sparse_top_k_categorical_accuracy: 0.9289 - val_loss: 1.2898 - val_sparse_categorical_accuracy: 0.6829 - val_sparse_top_k_categorical_accuracy: 0.8819 - lr: 3.0720e-04 - 7s/epoch - 47ms/step\n","Epoch 22/100\n","159/159 - 7s - loss: 0.8802 - sparse_categorical_accuracy: 0.7610 - sparse_top_k_categorical_accuracy: 0.9323 - val_loss: 1.3026 - val_sparse_categorical_accuracy: 0.6835 - val_sparse_top_k_categorical_accuracy: 0.8775 - lr: 3.0720e-04 - 7s/epoch - 43ms/step\n","Epoch 23/100\n","159/159 - 7s - loss: 0.8555 - sparse_categorical_accuracy: 0.7668 - sparse_top_k_categorical_accuracy: 0.9357 - val_loss: 1.2804 - val_sparse_categorical_accuracy: 0.6843 - val_sparse_top_k_categorical_accuracy: 0.8812 - lr: 3.0720e-04 - 7s/epoch - 43ms/step\n","Epoch 24/100\n","159/159 - 7s - loss: 0.8099 - sparse_categorical_accuracy: 0.7785 - sparse_top_k_categorical_accuracy: 0.9405 - val_loss: 1.2151 - val_sparse_categorical_accuracy: 0.7034 - val_sparse_top_k_categorical_accuracy: 0.8881 - lr: 3.0720e-04 - 7s/epoch - 47ms/step\n","Epoch 25/100\n","159/159 - 7s - loss: 0.7896 - sparse_categorical_accuracy: 0.7840 - sparse_top_k_categorical_accuracy: 0.9415 - val_loss: 1.2234 - val_sparse_categorical_accuracy: 0.7028 - val_sparse_top_k_categorical_accuracy: 0.8872 - lr: 3.0720e-04 - 7s/epoch - 42ms/step\n","Epoch 26/100\n","159/159 - 7s - loss: 0.7598 - sparse_categorical_accuracy: 0.7893 - sparse_top_k_categorical_accuracy: 0.9464 - val_loss: 1.1775 - val_sparse_categorical_accuracy: 0.7187 - val_sparse_top_k_categorical_accuracy: 0.8941 - lr: 3.0720e-04 - 7s/epoch - 43ms/step\n","Epoch 27/100\n","159/159 - 7s - loss: 0.7318 - sparse_categorical_accuracy: 0.7973 - sparse_top_k_categorical_accuracy: 0.9491 - val_loss: 1.1798 - val_sparse_categorical_accuracy: 0.7129 - val_sparse_top_k_categorical_accuracy: 0.8912 - lr: 3.0720e-04 - 7s/epoch - 42ms/step\n","Epoch 28/100\n","\n","Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0002457600086927414.\n","159/159 - 7s - loss: 0.7014 - sparse_categorical_accuracy: 0.8041 - sparse_top_k_categorical_accuracy: 0.9520 - val_loss: 1.2667 - val_sparse_categorical_accuracy: 0.7021 - val_sparse_top_k_categorical_accuracy: 0.8831 - lr: 3.0720e-04 - 7s/epoch - 42ms/step\n","Epoch 29/100\n","159/159 - 7s - loss: 0.6438 - sparse_categorical_accuracy: 0.8211 - sparse_top_k_categorical_accuracy: 0.9576 - val_loss: 1.1628 - val_sparse_categorical_accuracy: 0.7235 - val_sparse_top_k_categorical_accuracy: 0.8942 - lr: 2.4576e-04 - 7s/epoch - 42ms/step\n","Epoch 30/100\n","159/159 - 6s - loss: 0.6116 - sparse_categorical_accuracy: 0.8285 - sparse_top_k_categorical_accuracy: 0.9611 - val_loss: 1.2237 - val_sparse_categorical_accuracy: 0.7078 - val_sparse_top_k_categorical_accuracy: 0.8873 - lr: 2.4576e-04 - 6s/epoch - 41ms/step\n","Epoch 31/100\n","\n","Epoch 31: ReduceLROnPlateau reducing learning rate to 0.00019660801626741886.\n","159/159 - 7s - loss: 0.5962 - sparse_categorical_accuracy: 0.8324 - sparse_top_k_categorical_accuracy: 0.9636 - val_loss: 1.1777 - val_sparse_categorical_accuracy: 0.7219 - val_sparse_top_k_categorical_accuracy: 0.8942 - lr: 2.4576e-04 - 7s/epoch - 42ms/step\n","Epoch 32/100\n","159/159 - 7s - loss: 0.5465 - sparse_categorical_accuracy: 0.8458 - sparse_top_k_categorical_accuracy: 0.9680 - val_loss: 1.1022 - val_sparse_categorical_accuracy: 0.7394 - val_sparse_top_k_categorical_accuracy: 0.9004 - lr: 1.9661e-04 - 7s/epoch - 42ms/step\n","Epoch 33/100\n","159/159 - 7s - loss: 0.5298 - sparse_categorical_accuracy: 0.8506 - sparse_top_k_categorical_accuracy: 0.9691 - val_loss: 1.1174 - val_sparse_categorical_accuracy: 0.7385 - val_sparse_top_k_categorical_accuracy: 0.9004 - lr: 1.9661e-04 - 7s/epoch - 42ms/step\n","Epoch 34/100\n","\n","Epoch 34: ReduceLROnPlateau reducing learning rate to 0.0001572864130139351.\n","159/159 - 7s - loss: 0.5096 - sparse_categorical_accuracy: 0.8554 - sparse_top_k_categorical_accuracy: 0.9715 - val_loss: 1.1519 - val_sparse_categorical_accuracy: 0.7270 - val_sparse_top_k_categorical_accuracy: 0.8993 - lr: 1.9661e-04 - 7s/epoch - 42ms/step\n","Epoch 35/100\n","159/159 - 7s - loss: 0.4746 - sparse_categorical_accuracy: 0.8666 - sparse_top_k_categorical_accuracy: 0.9750 - val_loss: 1.1057 - val_sparse_categorical_accuracy: 0.7417 - val_sparse_top_k_categorical_accuracy: 0.9027 - lr: 1.5729e-04 - 7s/epoch - 43ms/step\n","Epoch 36/100\n","\n","Epoch 36: ReduceLROnPlateau reducing learning rate to 0.00012582913041114807.\n","159/159 - 7s - loss: 0.4615 - sparse_categorical_accuracy: 0.8694 - sparse_top_k_categorical_accuracy: 0.9760 - val_loss: 1.1031 - val_sparse_categorical_accuracy: 0.7421 - val_sparse_top_k_categorical_accuracy: 0.9034 - lr: 1.5729e-04 - 7s/epoch - 43ms/step\n","Epoch 37/100\n","159/159 - 7s - loss: 0.4284 - sparse_categorical_accuracy: 0.8789 - sparse_top_k_categorical_accuracy: 0.9789 - val_loss: 1.0480 - val_sparse_categorical_accuracy: 0.7559 - val_sparse_top_k_categorical_accuracy: 0.9083 - lr: 1.2583e-04 - 7s/epoch - 47ms/step\n","Epoch 38/100\n","159/159 - 7s - loss: 0.4188 - sparse_categorical_accuracy: 0.8819 - sparse_top_k_categorical_accuracy: 0.9797 - val_loss: 1.0907 - val_sparse_categorical_accuracy: 0.7475 - val_sparse_top_k_categorical_accuracy: 0.9039 - lr: 1.2583e-04 - 7s/epoch - 42ms/step\n","Epoch 39/100\n","\n","Epoch 39: ReduceLROnPlateau reducing learning rate to 0.00010066330432891847.\n","159/159 - 6s - loss: 0.4050 - sparse_categorical_accuracy: 0.8860 - sparse_top_k_categorical_accuracy: 0.9806 - val_loss: 1.0948 - val_sparse_categorical_accuracy: 0.7496 - val_sparse_top_k_categorical_accuracy: 0.9037 - lr: 1.2583e-04 - 6s/epoch - 41ms/step\n","Epoch 40/100\n","159/159 - 7s - loss: 0.3844 - sparse_categorical_accuracy: 0.8912 - sparse_top_k_categorical_accuracy: 0.9823 - val_loss: 1.0512 - val_sparse_categorical_accuracy: 0.7578 - val_sparse_top_k_categorical_accuracy: 0.9097 - lr: 1.0066e-04 - 7s/epoch - 42ms/step\n","Epoch 41/100\n","\n","Epoch 41: ReduceLROnPlateau reducing learning rate to 8.053064229898156e-05.\n","159/159 - 7s - loss: 0.3710 - sparse_categorical_accuracy: 0.8956 - sparse_top_k_categorical_accuracy: 0.9834 - val_loss: 1.0616 - val_sparse_categorical_accuracy: 0.7591 - val_sparse_top_k_categorical_accuracy: 0.9064 - lr: 1.0066e-04 - 7s/epoch - 41ms/step\n","Epoch 42/100\n","159/159 - 7s - loss: 0.3548 - sparse_categorical_accuracy: 0.9002 - sparse_top_k_categorical_accuracy: 0.9851 - val_loss: 1.0350 - val_sparse_categorical_accuracy: 0.7611 - val_sparse_top_k_categorical_accuracy: 0.9087 - lr: 8.0531e-05 - 7s/epoch - 42ms/step\n","Epoch 43/100\n","159/159 - 7s - loss: 0.3474 - sparse_categorical_accuracy: 0.9021 - sparse_top_k_categorical_accuracy: 0.9859 - val_loss: 1.0600 - val_sparse_categorical_accuracy: 0.7613 - val_sparse_top_k_categorical_accuracy: 0.9084 - lr: 8.0531e-05 - 7s/epoch - 43ms/step\n","Epoch 44/100\n","159/159 - 7s - loss: 0.3361 - sparse_categorical_accuracy: 0.9050 - sparse_top_k_categorical_accuracy: 0.9866 - val_loss: 1.0210 - val_sparse_categorical_accuracy: 0.7687 - val_sparse_top_k_categorical_accuracy: 0.9120 - lr: 8.0531e-05 - 7s/epoch - 47ms/step\n","Epoch 45/100\n","159/159 - 7s - loss: 0.3337 - sparse_categorical_accuracy: 0.9052 - sparse_top_k_categorical_accuracy: 0.9871 - val_loss: 1.0463 - val_sparse_categorical_accuracy: 0.7638 - val_sparse_top_k_categorical_accuracy: 0.9083 - lr: 8.0531e-05 - 7s/epoch - 46ms/step\n","Epoch 46/100\n","\n","Epoch 46: ReduceLROnPlateau reducing learning rate to 6.442451267503202e-05.\n","159/159 - 7s - loss: 0.3290 - sparse_categorical_accuracy: 0.9071 - sparse_top_k_categorical_accuracy: 0.9874 - val_loss: 1.0364 - val_sparse_categorical_accuracy: 0.7672 - val_sparse_top_k_categorical_accuracy: 0.9117 - lr: 8.0531e-05 - 7s/epoch - 42ms/step\n","Epoch 47/100\n","159/159 - 7s - loss: 0.3162 - sparse_categorical_accuracy: 0.9110 - sparse_top_k_categorical_accuracy: 0.9887 - val_loss: 1.0554 - val_sparse_categorical_accuracy: 0.7633 - val_sparse_top_k_categorical_accuracy: 0.9103 - lr: 6.4425e-05 - 7s/epoch - 43ms/step\n","Epoch 48/100\n","\n","Epoch 48: ReduceLROnPlateau reducing learning rate to 5.1539612468332055e-05.\n","159/159 - 7s - loss: 0.3050 - sparse_categorical_accuracy: 0.9144 - sparse_top_k_categorical_accuracy: 0.9889 - val_loss: 1.0604 - val_sparse_categorical_accuracy: 0.7596 - val_sparse_top_k_categorical_accuracy: 0.9091 - lr: 6.4425e-05 - 7s/epoch - 42ms/step\n","Epoch 49/100\n","159/159 - 7s - loss: 0.2941 - sparse_categorical_accuracy: 0.9181 - sparse_top_k_categorical_accuracy: 0.9902 - val_loss: 1.0297 - val_sparse_categorical_accuracy: 0.7696 - val_sparse_top_k_categorical_accuracy: 0.9123 - lr: 5.1540e-05 - 7s/epoch - 42ms/step\n","Epoch 50/100\n","\n","Epoch 50: ReduceLROnPlateau reducing learning rate to 4.1231690556742254e-05.\n","159/159 - 7s - loss: 0.2913 - sparse_categorical_accuracy: 0.9184 - sparse_top_k_categorical_accuracy: 0.9902 - val_loss: 1.0654 - val_sparse_categorical_accuracy: 0.7628 - val_sparse_top_k_categorical_accuracy: 0.9101 - lr: 5.1540e-05 - 7s/epoch - 42ms/step\n","Epoch 51/100\n","159/159 - 6s - loss: 0.2838 - sparse_categorical_accuracy: 0.9209 - sparse_top_k_categorical_accuracy: 0.9910 - val_loss: 1.0443 - val_sparse_categorical_accuracy: 0.7658 - val_sparse_top_k_categorical_accuracy: 0.9105 - lr: 4.1232e-05 - 6s/epoch - 41ms/step\n","Epoch 52/100\n","\n","Epoch 52: ReduceLROnPlateau reducing learning rate to 3.298535302747041e-05.\n","159/159 - 6s - loss: 0.2782 - sparse_categorical_accuracy: 0.9230 - sparse_top_k_categorical_accuracy: 0.9909 - val_loss: 1.0321 - val_sparse_categorical_accuracy: 0.7687 - val_sparse_top_k_categorical_accuracy: 0.9134 - lr: 4.1232e-05 - 6s/epoch - 40ms/step\n","Epoch 53/100\n","159/159 - 7s - loss: 0.2718 - sparse_categorical_accuracy: 0.9245 - sparse_top_k_categorical_accuracy: 0.9911 - val_loss: 1.0269 - val_sparse_categorical_accuracy: 0.7704 - val_sparse_top_k_categorical_accuracy: 0.9134 - lr: 3.2985e-05 - 7s/epoch - 42ms/step\n","Epoch 54/100\n","\n","Epoch 54: ReduceLROnPlateau reducing learning rate to 2.6388283004052937e-05.\n","159/159 - 7s - loss: 0.2681 - sparse_categorical_accuracy: 0.9261 - sparse_top_k_categorical_accuracy: 0.9915 - val_loss: 1.0238 - val_sparse_categorical_accuracy: 0.7711 - val_sparse_top_k_categorical_accuracy: 0.9136 - lr: 3.2985e-05 - 7s/epoch - 43ms/step\n","Epoch 55/100\n","159/159 - 7s - loss: 0.2625 - sparse_categorical_accuracy: 0.9281 - sparse_top_k_categorical_accuracy: 0.9921 - val_loss: 1.0208 - val_sparse_categorical_accuracy: 0.7738 - val_sparse_top_k_categorical_accuracy: 0.9131 - lr: 2.6388e-05 - 7s/epoch - 42ms/step\n","Epoch 56/100\n","159/159 - 7s - loss: 0.2611 - sparse_categorical_accuracy: 0.9275 - sparse_top_k_categorical_accuracy: 0.9926 - val_loss: 1.0267 - val_sparse_categorical_accuracy: 0.7715 - val_sparse_top_k_categorical_accuracy: 0.9135 - lr: 2.6388e-05 - 7s/epoch - 42ms/step\n","Epoch 57/100\n","159/159 - 7s - loss: 0.2564 - sparse_categorical_accuracy: 0.9290 - sparse_top_k_categorical_accuracy: 0.9924 - val_loss: 1.0205 - val_sparse_categorical_accuracy: 0.7723 - val_sparse_top_k_categorical_accuracy: 0.9123 - lr: 2.6388e-05 - 7s/epoch - 42ms/step\n","Epoch 58/100\n","159/159 - 7s - loss: 0.2537 - sparse_categorical_accuracy: 0.9291 - sparse_top_k_categorical_accuracy: 0.9928 - val_loss: 1.0261 - val_sparse_categorical_accuracy: 0.7724 - val_sparse_top_k_categorical_accuracy: 0.9129 - lr: 2.6388e-05 - 7s/epoch - 43ms/step\n","Epoch 59/100\n","\n","Epoch 59: ReduceLROnPlateau reducing learning rate to 2.1110626403242352e-05.\n","159/159 - 7s - loss: 0.2521 - sparse_categorical_accuracy: 0.9304 - sparse_top_k_categorical_accuracy: 0.9930 - val_loss: 1.0328 - val_sparse_categorical_accuracy: 0.7720 - val_sparse_top_k_categorical_accuracy: 0.9138 - lr: 2.6388e-05 - 7s/epoch - 42ms/step\n","Epoch 60/100\n","Restoring model weights from the end of the best epoch: 55.\n","159/159 - 7s - loss: 0.2516 - sparse_categorical_accuracy: 0.9304 - sparse_top_k_categorical_accuracy: 0.9932 - val_loss: 1.0291 - val_sparse_categorical_accuracy: 0.7715 - val_sparse_top_k_categorical_accuracy: 0.9133 - lr: 2.1111e-05 - 7s/epoch - 42ms/step\n","Epoch 60: early stopping\n","27/27 - 2s - 2s/epoch - 56ms/step\n","#########################\n","### Evaluation Metrics\n","420/420 [==============================] - 3s 6ms/step - loss: 1.0208 - sparse_categorical_accuracy: 0.7738 - sparse_top_k_categorical_accuracy: 0.9131\n","14/14 [==============================] - 1s 39ms/step\n","(13417, 250)\n","\n","\n","... CLASSWISE CONFUSION MATRIX... \n","\n","Class 228  (    uncle    )  -->  Accuracy: 0.92, Precision: 0.97, Recall: 0.94, F1 Score: 0.95\n","Class 31   (    brown    )  -->  Accuracy: 0.92, Precision: 0.95, Recall: 0.95, F1 Score: 0.95\n","Class 34   ( callonphone )  -->  Accuracy: 0.91, Precision: 0.97, Recall: 0.92, F1 Score: 0.94\n","Class 119  (    horse    )  -->  Accuracy: 0.91, Precision: 0.94, Recall: 0.94, F1 Score: 0.94\n","Class 50   (     cow     )  -->  Accuracy: 0.90, Precision: 0.95, Recall: 0.93, F1 Score: 0.94\n","Class 49   (    clown    )  -->  Accuracy: 0.90, Precision: 0.95, Recall: 0.93, F1 Score: 0.94\n","Class 165  (     owl     )  -->  Accuracy: 0.88, Precision: 0.92, Recall: 0.92, F1 Score: 0.92\n","Class 234  (    water    )  -->  Accuracy: 0.88, Precision: 0.90, Recall: 0.94, F1 Score: 0.92\n","Class 2    (  airplane   )  -->  Accuracy: 0.87, Precision: 0.89, Recall: 0.94, F1 Score: 0.92\n","Class 230  (     up      )  -->  Accuracy: 0.88, Precision: 0.94, Recall: 0.89, F1 Score: 0.92\n","Class 146  (    moon     )  -->  Accuracy: 0.88, Precision: 0.94, Recall: 0.89, F1 Score: 0.92\n","Class 240  (     why     )  -->  Accuracy: 0.88, Precision: 0.92, Recall: 0.91, F1 Score: 0.92\n","Class 86   (   flower    )  -->  Accuracy: 0.87, Precision: 0.91, Recall: 0.92, F1 Score: 0.91\n","Class 229  (  underwear  )  -->  Accuracy: 0.88, Precision: 0.97, Recall: 0.86, F1 Score: 0.91\n","Class 103  (     gum     )  -->  Accuracy: 0.87, Precision: 0.93, Recall: 0.89, F1 Score: 0.91\n","Class 198  (    sick     )  -->  Accuracy: 0.88, Precision: 1.00, Recall: 0.83, F1 Score: 0.91\n","Class 245  (  yesterday  )  -->  Accuracy: 0.86, Precision: 0.86, Recall: 0.96, F1 Score: 0.91\n","Class 51   (   cowboy    )  -->  Accuracy: 0.86, Precision: 0.88, Recall: 0.93, F1 Score: 0.91\n","Class 32   (     bug     )  -->  Accuracy: 0.86, Precision: 0.91, Recall: 0.90, F1 Score: 0.90\n","Class 122  (  icecream   )  -->  Accuracy: 0.86, Precision: 0.88, Recall: 0.93, F1 Score: 0.90\n","Class 243  (   yellow    )  -->  Accuracy: 0.86, Precision: 0.90, Recall: 0.90, F1 Score: 0.90\n","Class 193  (     see     )  -->  Accuracy: 0.85, Precision: 0.86, Recall: 0.93, F1 Score: 0.89\n","Class 121  (   hungry    )  -->  Accuracy: 0.85, Precision: 0.91, Recall: 0.87, F1 Score: 0.89\n","Class 117  (    high     )  -->  Accuracy: 0.85, Precision: 0.90, Recall: 0.88, F1 Score: 0.89\n","Class 174  (   police    )  -->  Accuracy: 0.85, Precision: 0.89, Recall: 0.89, F1 Score: 0.89\n","Class 239  (     who     )  -->  Accuracy: 0.85, Precision: 0.91, Recall: 0.87, F1 Score: 0.89\n","Class 194  (    shhh     )  -->  Accuracy: 0.84, Precision: 0.84, Recall: 0.94, F1 Score: 0.89\n","Class 29   (     boy     )  -->  Accuracy: 0.84, Precision: 0.88, Recall: 0.89, F1 Score: 0.89\n","Class 94   (    girl     )  -->  Accuracy: 0.84, Precision: 0.86, Recall: 0.91, F1 Score: 0.88\n","Class 242  (    wolf     )  -->  Accuracy: 0.84, Precision: 0.90, Recall: 0.87, F1 Score: 0.88\n","Class 8    (    apple    )  -->  Accuracy: 0.84, Precision: 0.91, Recall: 0.86, F1 Score: 0.88\n","Class 24   (    black    )  -->  Accuracy: 0.84, Precision: 0.91, Recall: 0.86, F1 Score: 0.88\n","Class 158  (    nuts     )  -->  Accuracy: 0.84, Precision: 0.86, Recall: 0.90, F1 Score: 0.88\n","Class 118  (    home     )  -->  Accuracy: 0.84, Precision: 0.87, Recall: 0.89, F1 Score: 0.88\n","Class 59   (    doll     )  -->  Accuracy: 0.83, Precision: 0.85, Recall: 0.90, F1 Score: 0.88\n","Class 182  (    radio    )  -->  Accuracy: 0.84, Precision: 0.93, Recall: 0.83, F1 Score: 0.88\n","Class 54   (    cute     )  -->  Accuracy: 0.84, Precision: 0.92, Recall: 0.83, F1 Score: 0.88\n","Class 88   (     for     )  -->  Accuracy: 0.83, Precision: 0.86, Recall: 0.89, F1 Score: 0.88\n","Class 133  (    lion     )  -->  Accuracy: 0.84, Precision: 0.92, Recall: 0.83, F1 Score: 0.87\n","Class 219  (    tiger    )  -->  Accuracy: 0.83, Precision: 0.88, Recall: 0.86, F1 Score: 0.87\n","Class 10   (    aunt     )  -->  Accuracy: 0.83, Precision: 0.84, Recall: 0.91, F1 Score: 0.87\n","Class 224  ( toothbrush  )  -->  Accuracy: 0.83, Precision: 0.86, Recall: 0.88, F1 Score: 0.87\n","Class 72   (     eye     )  -->  Accuracy: 0.83, Precision: 0.88, Recall: 0.86, F1 Score: 0.87\n","Class 78   (    find     )  -->  Accuracy: 0.83, Precision: 0.88, Recall: 0.86, F1 Score: 0.87\n","Class 120  (     hot     )  -->  Accuracy: 0.83, Precision: 0.88, Recall: 0.86, F1 Score: 0.87\n","Class 110  (    head     )  -->  Accuracy: 0.82, Precision: 0.84, Recall: 0.90, F1 Score: 0.87\n","Class 104  (    hair     )  -->  Accuracy: 0.82, Precision: 0.87, Recall: 0.87, F1 Score: 0.87\n","Class 159  (     old     )  -->  Accuracy: 0.83, Precision: 0.91, Recall: 0.82, F1 Score: 0.86\n","Class 60   (   donkey    )  -->  Accuracy: 0.82, Precision: 0.86, Recall: 0.86, F1 Score: 0.86\n","Class 37   (   carrot    )  -->  Accuracy: 0.82, Precision: 0.84, Recall: 0.88, F1 Score: 0.86\n","Class 90   (    frog     )  -->  Accuracy: 0.82, Precision: 0.88, Recall: 0.84, F1 Score: 0.86\n","Class 73   (    face     )  -->  Accuracy: 0.82, Precision: 0.90, Recall: 0.82, F1 Score: 0.86\n","Class 82   (   fireman   )  -->  Accuracy: 0.82, Precision: 0.89, Recall: 0.83, F1 Score: 0.86\n","Class 63   (    drink    )  -->  Accuracy: 0.82, Precision: 0.86, Recall: 0.86, F1 Score: 0.86\n","Class 189  (     sad     )  -->  Accuracy: 0.82, Precision: 0.87, Recall: 0.85, F1 Score: 0.86\n","Class 196  (    shoe     )  -->  Accuracy: 0.82, Precision: 0.85, Recall: 0.87, F1 Score: 0.86\n","Class 213  (    taste    )  -->  Accuracy: 0.81, Precision: 0.83, Recall: 0.88, F1 Score: 0.85\n","Class 14   (   balloon   )  -->  Accuracy: 0.81, Precision: 0.84, Recall: 0.87, F1 Score: 0.85\n","Class 33   (     bye     )  -->  Accuracy: 0.80, Precision: 0.79, Recall: 0.92, F1 Score: 0.85\n","Class 178  (   pretty    )  -->  Accuracy: 0.81, Precision: 0.85, Recall: 0.85, F1 Score: 0.85\n","Class 77   (    feet     )  -->  Accuracy: 0.81, Precision: 0.88, Recall: 0.82, F1 Score: 0.85\n","Class 197  (   shower    )  -->  Accuracy: 0.81, Precision: 0.83, Recall: 0.87, F1 Score: 0.85\n","Class 162  (   orange    )  -->  Accuracy: 0.82, Precision: 0.91, Recall: 0.80, F1 Score: 0.85\n","Class 113  (    hello    )  -->  Accuracy: 0.81, Precision: 0.84, Recall: 0.85, F1 Score: 0.85\n","Class 155  (    nose     )  -->  Accuracy: 0.81, Precision: 0.84, Recall: 0.84, F1 Score: 0.84\n","Class 39   (   cereal    )  -->  Accuracy: 0.80, Precision: 0.80, Recall: 0.89, F1 Score: 0.84\n","Class 16   (   because   )  -->  Accuracy: 0.81, Precision: 0.86, Recall: 0.83, F1 Score: 0.84\n","Class 87   (    food     )  -->  Accuracy: 0.80, Precision: 0.79, Recall: 0.90, F1 Score: 0.84\n","Class 210  (     sun     )  -->  Accuracy: 0.80, Precision: 0.82, Recall: 0.87, F1 Score: 0.84\n","Class 238  (    white    )  -->  Accuracy: 0.82, Precision: 0.93, Recall: 0.76, F1 Score: 0.84\n","Class 195  (    shirt    )  -->  Accuracy: 0.80, Precision: 0.82, Recall: 0.85, F1 Score: 0.84\n","Class 101  (    grass    )  -->  Accuracy: 0.80, Precision: 0.85, Recall: 0.82, F1 Score: 0.84\n","Class 44   (  chocolate  )  -->  Accuracy: 0.80, Precision: 0.82, Recall: 0.85, F1 Score: 0.84\n","Class 151  (   napkin    )  -->  Accuracy: 0.80, Precision: 0.83, Recall: 0.84, F1 Score: 0.83\n","Class 157  (     now     )  -->  Accuracy: 0.80, Precision: 0.81, Recall: 0.86, F1 Score: 0.83\n","Class 207  (    store    )  -->  Accuracy: 0.80, Precision: 0.86, Recall: 0.81, F1 Score: 0.83\n","Class 172  (    pizza    )  -->  Accuracy: 0.81, Precision: 0.90, Recall: 0.78, F1 Score: 0.83\n","Class 173  (   please    )  -->  Accuracy: 0.80, Precision: 0.83, Recall: 0.83, F1 Score: 0.83\n","Class 100  (   grandpa   )  -->  Accuracy: 0.81, Precision: 0.89, Recall: 0.78, F1 Score: 0.83\n","Class 9    (     arm     )  -->  Accuracy: 0.79, Precision: 0.81, Recall: 0.85, F1 Score: 0.83\n","Class 83   (    first    )  -->  Accuracy: 0.79, Precision: 0.80, Recall: 0.86, F1 Score: 0.83\n","Class 148  (    mouse    )  -->  Accuracy: 0.79, Precision: 0.80, Recall: 0.85, F1 Score: 0.83\n","Class 57   (    dirty    )  -->  Accuracy: 0.80, Precision: 0.86, Recall: 0.79, F1 Score: 0.83\n","Class 93   (   giraffe   )  -->  Accuracy: 0.79, Precision: 0.80, Recall: 0.85, F1 Score: 0.83\n","Class 201  (    smile    )  -->  Accuracy: 0.79, Precision: 0.78, Recall: 0.88, F1 Score: 0.83\n","Class 23   (    bird     )  -->  Accuracy: 0.77, Precision: 0.72, Recall: 0.96, F1 Score: 0.82\n","Class 61   (    down     )  -->  Accuracy: 0.79, Precision: 0.80, Recall: 0.85, F1 Score: 0.82\n","Class 244  (     yes     )  -->  Accuracy: 0.79, Precision: 0.79, Recall: 0.86, F1 Score: 0.82\n","Class 123  (     if      )  -->  Accuracy: 0.79, Precision: 0.81, Recall: 0.84, F1 Score: 0.82\n","Class 47   (   closet    )  -->  Accuracy: 0.80, Precision: 0.85, Recall: 0.80, F1 Score: 0.82\n","Class 89   ( frenchfries )  -->  Accuracy: 0.80, Precision: 0.87, Recall: 0.77, F1 Score: 0.82\n","Class 203  (    snow     )  -->  Accuracy: 0.79, Precision: 0.80, Recall: 0.84, F1 Score: 0.82\n","Class 41   (    cheek    )  -->  Accuracy: 0.79, Precision: 0.85, Recall: 0.79, F1 Score: 0.82\n","Class 183  (    rain     )  -->  Accuracy: 0.80, Precision: 0.87, Recall: 0.77, F1 Score: 0.82\n","Class 91   (   garbage   )  -->  Accuracy: 0.80, Precision: 0.88, Recall: 0.76, F1 Score: 0.82\n","Class 209  (    stuck    )  -->  Accuracy: 0.79, Precision: 0.82, Recall: 0.82, F1 Score: 0.82\n","Class 139  (    make     )  -->  Accuracy: 0.79, Precision: 0.81, Recall: 0.82, F1 Score: 0.82\n","Class 75   (    farm     )  -->  Accuracy: 0.79, Precision: 0.82, Recall: 0.81, F1 Score: 0.81\n","Class 169  (    penny    )  -->  Accuracy: 0.80, Precision: 0.89, Recall: 0.75, F1 Score: 0.81\n","Class 202  (    snack    )  -->  Accuracy: 0.78, Precision: 0.81, Recall: 0.81, F1 Score: 0.81\n","Class 25   (    blow     )  -->  Accuracy: 0.79, Precision: 0.83, Recall: 0.79, F1 Score: 0.81\n","Class 153  (     no      )  -->  Accuracy: 0.78, Precision: 0.82, Recall: 0.80, F1 Score: 0.81\n","Class 43   (    chin     )  -->  Accuracy: 0.78, Precision: 0.77, Recall: 0.85, F1 Score: 0.81\n","Class 147  (   morning   )  -->  Accuracy: 0.78, Precision: 0.81, Recall: 0.81, F1 Score: 0.81\n","Class 241  (    will     )  -->  Accuracy: 0.79, Precision: 0.83, Recall: 0.79, F1 Score: 0.81\n","Class 12   (  backyard   )  -->  Accuracy: 0.78, Precision: 0.80, Recall: 0.81, F1 Score: 0.81\n","Class 30   (   brother   )  -->  Accuracy: 0.79, Precision: 0.89, Recall: 0.74, F1 Score: 0.80\n","Class 222  (   tongue    )  -->  Accuracy: 0.79, Precision: 0.88, Recall: 0.74, F1 Score: 0.80\n","Class 136  (    look     )  -->  Accuracy: 0.78, Precision: 0.82, Recall: 0.78, F1 Score: 0.80\n","Class 138  (     mad     )  -->  Accuracy: 0.78, Precision: 0.85, Recall: 0.75, F1 Score: 0.80\n","Class 214  (  thankyou   )  -->  Accuracy: 0.78, Precision: 0.78, Recall: 0.82, F1 Score: 0.80\n","Class 85   (    flag     )  -->  Accuracy: 0.78, Precision: 0.79, Recall: 0.81, F1 Score: 0.80\n","Class 131  (    later    )  -->  Accuracy: 0.77, Precision: 0.75, Recall: 0.86, F1 Score: 0.80\n","Class 212  (    talk     )  -->  Accuracy: 0.78, Precision: 0.82, Recall: 0.77, F1 Score: 0.80\n","Class 135  (   listen    )  -->  Accuracy: 0.76, Precision: 0.73, Recall: 0.88, F1 Score: 0.80\n","Class 52   (     cry     )  -->  Accuracy: 0.77, Precision: 0.75, Recall: 0.85, F1 Score: 0.80\n","Class 227  (    tree     )  -->  Accuracy: 0.78, Precision: 0.85, Recall: 0.75, F1 Score: 0.80\n","Class 206  (   sticky    )  -->  Accuracy: 0.78, Precision: 0.84, Recall: 0.76, F1 Score: 0.80\n","Class 225  (    touch    )  -->  Accuracy: 0.78, Precision: 0.85, Recall: 0.75, F1 Score: 0.80\n","Class 19   (     bee     )  -->  Accuracy: 0.77, Precision: 0.79, Recall: 0.79, F1 Score: 0.79\n","Class 171  (     pig     )  -->  Accuracy: 0.76, Precision: 0.72, Recall: 0.88, F1 Score: 0.79\n","Class 221  (  tomorrow   )  -->  Accuracy: 0.77, Precision: 0.77, Recall: 0.81, F1 Score: 0.79\n","Class 84   (    fish     )  -->  Accuracy: 0.77, Precision: 0.75, Recall: 0.83, F1 Score: 0.79\n","Class 140  (     man     )  -->  Accuracy: 0.78, Precision: 0.84, Recall: 0.75, F1 Score: 0.79\n","Class 226  (     toy     )  -->  Accuracy: 0.78, Precision: 0.82, Recall: 0.76, F1 Score: 0.79\n","Class 55   (     dad     )  -->  Accuracy: 0.75, Precision: 0.70, Recall: 0.91, F1 Score: 0.79\n","Class 177  (   pretend   )  -->  Accuracy: 0.78, Precision: 0.90, Recall: 0.70, F1 Score: 0.79\n","Class 48   (    cloud    )  -->  Accuracy: 0.78, Precision: 0.84, Recall: 0.74, F1 Score: 0.79\n","Class 0    (     TV      )  -->  Accuracy: 0.76, Precision: 0.74, Recall: 0.83, F1 Score: 0.79\n","Class 185  (     red     )  -->  Accuracy: 0.77, Precision: 0.78, Recall: 0.78, F1 Score: 0.78\n","Class 208  (    story    )  -->  Accuracy: 0.77, Precision: 0.81, Recall: 0.76, F1 Score: 0.78\n","Class 114  (     hen     )  -->  Accuracy: 0.77, Precision: 0.80, Recall: 0.77, F1 Score: 0.78\n","Class 112  ( helicopter  )  -->  Accuracy: 0.77, Precision: 0.81, Recall: 0.75, F1 Score: 0.78\n","Class 204  (   stairs    )  -->  Accuracy: 0.76, Precision: 0.76, Recall: 0.80, F1 Score: 0.78\n","Class 132  (    like     )  -->  Accuracy: 0.77, Precision: 0.80, Recall: 0.75, F1 Score: 0.78\n","Class 137  (    loud     )  -->  Accuracy: 0.75, Precision: 0.73, Recall: 0.83, F1 Score: 0.78\n","Class 69   (  elephant   )  -->  Accuracy: 0.77, Precision: 0.84, Recall: 0.72, F1 Score: 0.77\n","Class 246  (  yourself   )  -->  Accuracy: 0.76, Precision: 0.76, Recall: 0.79, F1 Score: 0.77\n","Class 154  (    noisy    )  -->  Accuracy: 0.77, Precision: 0.80, Recall: 0.75, F1 Score: 0.77\n","Class 68   (     ear     )  -->  Accuracy: 0.76, Precision: 0.75, Recall: 0.80, F1 Score: 0.77\n","Class 13   (     bad     )  -->  Accuracy: 0.75, Precision: 0.73, Recall: 0.82, F1 Score: 0.77\n","Class 70   (    empty    )  -->  Accuracy: 0.77, Precision: 0.85, Recall: 0.70, F1 Score: 0.77\n","Class 176  (    potty    )  -->  Accuracy: 0.76, Precision: 0.77, Recall: 0.76, F1 Score: 0.77\n","Class 186  (refrigerator )  -->  Accuracy: 0.78, Precision: 0.90, Recall: 0.67, F1 Score: 0.77\n","Class 156  (     not     )  -->  Accuracy: 0.76, Precision: 0.77, Recall: 0.77, F1 Score: 0.77\n","Class 145  (     mom     )  -->  Accuracy: 0.75, Precision: 0.74, Recall: 0.80, F1 Score: 0.76\n","Class 105  (    happy    )  -->  Accuracy: 0.75, Precision: 0.74, Recall: 0.79, F1 Score: 0.76\n","Class 129  (    kitty    )  -->  Accuracy: 0.76, Precision: 0.77, Recall: 0.76, F1 Score: 0.76\n","Class 141  (    many     )  -->  Accuracy: 0.74, Precision: 0.69, Recall: 0.86, F1 Score: 0.76\n","Class 66   (    dryer    )  -->  Accuracy: 0.75, Precision: 0.70, Recall: 0.83, F1 Score: 0.76\n","Class 166  (   pajamas   )  -->  Accuracy: 0.77, Precision: 0.83, Recall: 0.70, F1 Score: 0.76\n","Class 96   ( glasswindow )  -->  Accuracy: 0.75, Precision: 0.75, Recall: 0.77, F1 Score: 0.76\n","Class 128  (    kiss     )  -->  Accuracy: 0.76, Precision: 0.77, Recall: 0.75, F1 Score: 0.76\n","Class 130  (    lamp     )  -->  Accuracy: 0.76, Precision: 0.81, Recall: 0.71, F1 Score: 0.76\n","Class 218  (   thirsty   )  -->  Accuracy: 0.76, Precision: 0.82, Recall: 0.70, F1 Score: 0.76\n","Class 190  (    same     )  -->  Accuracy: 0.74, Precision: 0.68, Recall: 0.84, F1 Score: 0.75\n","Class 67   (    duck     )  -->  Accuracy: 0.75, Precision: 0.76, Recall: 0.74, F1 Score: 0.75\n","Class 217  (    think    )  -->  Accuracy: 0.73, Precision: 0.66, Recall: 0.88, F1 Score: 0.75\n","Class 81   (   finish    )  -->  Accuracy: 0.74, Precision: 0.69, Recall: 0.81, F1 Score: 0.75\n","Class 58   (     dog     )  -->  Accuracy: 0.75, Precision: 0.77, Recall: 0.73, F1 Score: 0.75\n","Class 144  (   mitten    )  -->  Accuracy: 0.76, Precision: 0.84, Recall: 0.67, F1 Score: 0.75\n","Class 181  (    quiet    )  -->  Accuracy: 0.75, Precision: 0.74, Recall: 0.76, F1 Score: 0.75\n","Class 26   (    blue     )  -->  Accuracy: 0.75, Precision: 0.73, Recall: 0.76, F1 Score: 0.75\n","Class 236  (    weus     )  -->  Accuracy: 0.75, Precision: 0.75, Recall: 0.75, F1 Score: 0.75\n","Class 164  (    owie     )  -->  Accuracy: 0.75, Precision: 0.74, Recall: 0.74, F1 Score: 0.74\n","Class 143  (   minemy    )  -->  Accuracy: 0.74, Precision: 0.68, Recall: 0.81, F1 Score: 0.74\n","Class 71   (    every    )  -->  Accuracy: 0.74, Precision: 0.73, Recall: 0.76, F1 Score: 0.74\n","Class 223  (    tooth    )  -->  Accuracy: 0.74, Precision: 0.73, Recall: 0.75, F1 Score: 0.74\n","Class 232  (    wait     )  -->  Accuracy: 0.74, Precision: 0.72, Recall: 0.76, F1 Score: 0.74\n","Class 98   (    goose    )  -->  Accuracy: 0.75, Precision: 0.78, Recall: 0.70, F1 Score: 0.74\n","Class 3    (     all     )  -->  Accuracy: 0.76, Precision: 0.83, Recall: 0.66, F1 Score: 0.74\n","Class 163  (   outside   )  -->  Accuracy: 0.73, Precision: 0.67, Recall: 0.82, F1 Score: 0.74\n","Class 191  (     say     )  -->  Accuracy: 0.74, Precision: 0.73, Recall: 0.74, F1 Score: 0.74\n","Class 6    (   another   )  -->  Accuracy: 0.74, Precision: 0.72, Recall: 0.75, F1 Score: 0.73\n","Class 102  (    green    )  -->  Accuracy: 0.74, Precision: 0.73, Recall: 0.73, F1 Score: 0.73\n","Class 99   (   grandma   )  -->  Accuracy: 0.74, Precision: 0.74, Recall: 0.72, F1 Score: 0.73\n","Class 211  (    table    )  -->  Accuracy: 0.73, Precision: 0.67, Recall: 0.80, F1 Score: 0.73\n","Class 142  (    milk     )  -->  Accuracy: 0.73, Precision: 0.67, Recall: 0.79, F1 Score: 0.73\n","Class 64   (    drop     )  -->  Accuracy: 0.73, Precision: 0.69, Recall: 0.77, F1 Score: 0.73\n","Class 247  (    yucky    )  -->  Accuracy: 0.74, Precision: 0.73, Recall: 0.73, F1 Score: 0.73\n","Class 184  (    read     )  -->  Accuracy: 0.74, Precision: 0.73, Recall: 0.72, F1 Score: 0.72\n","Class 248  (    zebra    )  -->  Accuracy: 0.74, Precision: 0.71, Recall: 0.73, F1 Score: 0.72\n","Class 215  (    that     )  -->  Accuracy: 0.73, Precision: 0.67, Recall: 0.78, F1 Score: 0.72\n","Class 36   (     car     )  -->  Accuracy: 0.74, Precision: 0.75, Recall: 0.69, F1 Score: 0.72\n","Class 56   (    dance    )  -->  Accuracy: 0.74, Precision: 0.73, Recall: 0.71, F1 Score: 0.72\n","Class 115  (   hesheit   )  -->  Accuracy: 0.74, Precision: 0.73, Recall: 0.70, F1 Score: 0.71\n","Class 65   (     dry     )  -->  Accuracy: 0.74, Precision: 0.76, Recall: 0.67, F1 Score: 0.71\n","Class 22   (   better    )  -->  Accuracy: 0.75, Precision: 0.86, Recall: 0.60, F1 Score: 0.71\n","Class 127  (    jump     )  -->  Accuracy: 0.74, Precision: 0.73, Recall: 0.69, F1 Score: 0.71\n","Class 107  (    hate     )  -->  Accuracy: 0.73, Precision: 0.69, Recall: 0.73, F1 Score: 0.71\n","Class 4    (  alligator  )  -->  Accuracy: 0.72, Precision: 0.66, Recall: 0.76, F1 Score: 0.71\n","Class 20   (   before    )  -->  Accuracy: 0.72, Precision: 0.66, Recall: 0.76, F1 Score: 0.71\n","Class 97   (     go      )  -->  Accuracy: 0.76, Precision: 0.92, Recall: 0.58, F1 Score: 0.71\n","Class 237  (    where    )  -->  Accuracy: 0.71, Precision: 0.63, Recall: 0.80, F1 Score: 0.71\n","Class 235  (     wet     )  -->  Accuracy: 0.72, Precision: 0.67, Recall: 0.75, F1 Score: 0.71\n","Class 79   (    fine     )  -->  Accuracy: 0.71, Precision: 0.62, Recall: 0.79, F1 Score: 0.70\n","Class 109  (   haveto    )  -->  Accuracy: 0.72, Precision: 0.69, Recall: 0.70, F1 Score: 0.69\n","Class 134  (    lips     )  -->  Accuracy: 0.72, Precision: 0.69, Recall: 0.70, F1 Score: 0.69\n","Class 188  (    room     )  -->  Accuracy: 0.73, Precision: 0.76, Recall: 0.64, F1 Score: 0.69\n","Class 80   (   finger    )  -->  Accuracy: 0.73, Precision: 0.73, Recall: 0.65, F1 Score: 0.69\n","Class 92   (    gift     )  -->  Accuracy: 0.71, Precision: 0.63, Recall: 0.75, F1 Score: 0.69\n","Class 62   (   drawer    )  -->  Accuracy: 0.72, Precision: 0.70, Recall: 0.67, F1 Score: 0.69\n","Class 53   (     cut     )  -->  Accuracy: 0.73, Precision: 0.73, Recall: 0.64, F1 Score: 0.68\n","Class 27   (    boat     )  -->  Accuracy: 0.73, Precision: 0.73, Recall: 0.64, F1 Score: 0.68\n","Class 175  (    pool     )  -->  Accuracy: 0.71, Precision: 0.64, Recall: 0.72, F1 Score: 0.68\n","Class 40   (    chair    )  -->  Accuracy: 0.70, Precision: 0.60, Recall: 0.77, F1 Score: 0.67\n","Class 18   (   bedroom   )  -->  Accuracy: 0.72, Precision: 0.73, Recall: 0.61, F1 Score: 0.67\n","Class 38   (     cat     )  -->  Accuracy: 0.71, Precision: 0.67, Recall: 0.67, F1 Score: 0.67\n","Class 106  (     hat     )  -->  Accuracy: 0.72, Precision: 0.67, Recall: 0.66, F1 Score: 0.67\n","Class 5    (   animal    )  -->  Accuracy: 0.70, Precision: 0.62, Recall: 0.71, F1 Score: 0.66\n","Class 17   (     bed     )  -->  Accuracy: 0.69, Precision: 0.56, Recall: 0.80, F1 Score: 0.66\n","Class 116  (    hide     )  -->  Accuracy: 0.71, Precision: 0.65, Recall: 0.67, F1 Score: 0.66\n","Class 28   (    book     )  -->  Accuracy: 0.73, Precision: 0.76, Recall: 0.58, F1 Score: 0.66\n","Class 76   (    fast     )  -->  Accuracy: 0.71, Precision: 0.67, Recall: 0.65, F1 Score: 0.66\n","Class 180  (   puzzle    )  -->  Accuracy: 0.71, Precision: 0.66, Recall: 0.65, F1 Score: 0.65\n","Class 179  (    puppy    )  -->  Accuracy: 0.71, Precision: 0.68, Recall: 0.62, F1 Score: 0.65\n","Class 111  (    hear     )  -->  Accuracy: 0.71, Precision: 0.65, Recall: 0.64, F1 Score: 0.65\n","Class 125  (   jacket    )  -->  Accuracy: 0.70, Precision: 0.62, Recall: 0.67, F1 Score: 0.65\n","Class 46   (    close    )  -->  Accuracy: 0.72, Precision: 0.73, Recall: 0.58, F1 Score: 0.65\n","Class 35   (     can     )  -->  Accuracy: 0.71, Precision: 0.65, Recall: 0.63, F1 Score: 0.64\n","Class 152  (    night    )  -->  Accuracy: 0.70, Precision: 0.64, Recall: 0.65, F1 Score: 0.64\n","Class 220  (    time     )  -->  Accuracy: 0.71, Precision: 0.67, Recall: 0.62, F1 Score: 0.64\n","Class 192  (  scissors   )  -->  Accuracy: 0.68, Precision: 0.56, Recall: 0.71, F1 Score: 0.63\n","Class 108  (    have     )  -->  Accuracy: 0.71, Precision: 0.68, Recall: 0.58, F1 Score: 0.62\n","Class 249  (   zipper    )  -->  Accuracy: 0.69, Precision: 0.60, Recall: 0.65, F1 Score: 0.62\n","Class 15   (    bath     )  -->  Accuracy: 0.69, Precision: 0.57, Recall: 0.68, F1 Score: 0.62\n","Class 231  (   vacuum    )  -->  Accuracy: 0.69, Precision: 0.57, Recall: 0.67, F1 Score: 0.62\n","Class 124  (    into     )  -->  Accuracy: 0.70, Precision: 0.62, Recall: 0.61, F1 Score: 0.61\n","Class 161  (    open     )  -->  Accuracy: 0.68, Precision: 0.53, Recall: 0.70, F1 Score: 0.61\n","Class 150  (     nap     )  -->  Accuracy: 0.71, Precision: 0.72, Recall: 0.52, F1 Score: 0.60\n","Class 205  (    stay     )  -->  Accuracy: 0.69, Precision: 0.59, Recall: 0.59, F1 Score: 0.59\n","Class 160  (     on      )  -->  Accuracy: 0.67, Precision: 0.52, Recall: 0.68, F1 Score: 0.59\n","Class 42   (    child    )  -->  Accuracy: 0.69, Precision: 0.57, Recall: 0.60, F1 Score: 0.59\n","Class 126  (    jeans    )  -->  Accuracy: 0.69, Precision: 0.57, Recall: 0.58, F1 Score: 0.58\n","Class 187  (    ride     )  -->  Accuracy: 0.70, Precision: 0.67, Recall: 0.50, F1 Score: 0.57\n","Class 168  (   pencil    )  -->  Accuracy: 0.69, Precision: 0.58, Recall: 0.55, F1 Score: 0.57\n","Class 199  (    sleep    )  -->  Accuracy: 0.67, Precision: 0.51, Recall: 0.65, F1 Score: 0.57\n","Class 74   (    fall     )  -->  Accuracy: 0.68, Precision: 0.53, Recall: 0.60, F1 Score: 0.56\n","Class 216  (    there    )  -->  Accuracy: 0.68, Precision: 0.57, Recall: 0.55, F1 Score: 0.56\n","Class 7    (     any     )  -->  Accuracy: 0.70, Precision: 0.66, Recall: 0.48, F1 Score: 0.55\n","Class 170  (   person    )  -->  Accuracy: 0.69, Precision: 0.62, Recall: 0.50, F1 Score: 0.55\n","Class 45   (    clean    )  -->  Accuracy: 0.66, Precision: 0.49, Recall: 0.60, F1 Score: 0.54\n","Class 200  (   sleepy    )  -->  Accuracy: 0.67, Precision: 0.53, Recall: 0.54, F1 Score: 0.53\n","Class 11   (    awake    )  -->  Accuracy: 0.67, Precision: 0.50, Recall: 0.49, F1 Score: 0.50\n","Class 233  (    wake     )  -->  Accuracy: 0.68, Precision: 0.57, Recall: 0.44, F1 Score: 0.50\n","Class 149  (    mouth    )  -->  Accuracy: 0.68, Precision: 0.59, Recall: 0.43, F1 Score: 0.49\n","Class 21   (   beside    )  -->  Accuracy: 0.66, Precision: 0.49, Recall: 0.47, F1 Score: 0.48\n","Class 1    (    after    )  -->  Accuracy: 0.66, Precision: 0.47, Recall: 0.47, F1 Score: 0.47\n","Class 95   (    give     )  -->  Accuracy: 0.66, Precision: 0.49, Recall: 0.44, F1 Score: 0.46\n","Class 167  (     pen     )  -->  Accuracy: 0.66, Precision: 0.45, Recall: 0.44, F1 Score: 0.45\n","#########################\n","Overall Metrics\n","accuracy 0.7737944398896922\n","f1_score 0.7737431730875807\n","precision 0.7791361532541089\n","recall 0.7737944398896922\n","[2023-05-06 19:02:15,199][absl][WARNING] - Found untraced functions such as feature_gen_layer_call_fn, feature_gen_layer_call_and_return_conditional_losses, dense_layer_call_fn, dense_layer_call_and_return_conditional_losses, activation_layer_call_fn while saving (showing 5 of 28). These functions will not be directly callable after loading.\n","[2023-05-06 19:02:16,807][tensorflow][INFO] - Assets written to: /tmp/tmpgv64r7hb/assets\n"]}],"source":["!python3 trainer.py"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":4}
